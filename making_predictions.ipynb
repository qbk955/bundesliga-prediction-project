{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.feature_selection import RFE\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Preparing DateTypes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('bundesliga_matches_final_show.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                                 object\n",
       "time                                 object\n",
       "comp                                 object\n",
       "round                                object\n",
       "day                                  object\n",
       "venue                                object\n",
       "result                               object\n",
       "gf                                    int64\n",
       "ga                                    int64\n",
       "xg                                  float64\n",
       "xga                                 float64\n",
       "poss                                  int64\n",
       "opponent_gf                           int64\n",
       "opponent_ga                           int64\n",
       "opponent_xg                         float64\n",
       "opponent_xga                        float64\n",
       "opponent_poss                         int64\n",
       "attendance                            int64\n",
       "captain                              object\n",
       "opponent_captain                     object\n",
       "home_team_formation                  object\n",
       "away_team_formation                  object\n",
       "referee                              object\n",
       "sh                                    int64\n",
       "sot                                   int64\n",
       "dist                                float64\n",
       "fk                                  float64\n",
       "pk                                    int64\n",
       "pkatt                                 int64\n",
       "opponent_sh                           int64\n",
       "opponent_sot                          int64\n",
       "opponent_dist                       float64\n",
       "opponent_fk                         float64\n",
       "opponent_pk                           int64\n",
       "opponent_pkatt                        int64\n",
       "season                                int64\n",
       "team                                 object\n",
       "opponent                             object\n",
       "team_salary                           int64\n",
       "opponent_team_salary                  int64\n",
       "gf_last_4_games                     float64\n",
       "ga_last_4_games                     float64\n",
       "xga_last_4_games                    float64\n",
       "avg_points_last_4_games             float64\n",
       "opponent_gf_last_4_games            float64\n",
       "opponent_ga_last_4_games            float64\n",
       "opponent_xga_last_4_games           float64\n",
       "opponent_avg_points_last_4_games    float64\n",
       "team_overall                          int64\n",
       "team_attack                           int64\n",
       "team_midfield                         int64\n",
       "team_defense                          int64\n",
       "opponent_overall                      int64\n",
       "opponent_attack                       int64\n",
       "opponent_midfield                     int64\n",
       "opponent_defense                      int64\n",
       "sh_last_4_games                     float64\n",
       "sot_last_4_games                    float64\n",
       "dist_last_4_games                   float64\n",
       "fk_last_4_games                     float64\n",
       "pk_last_4_games                     float64\n",
       "pkatt_last_4_games                  float64\n",
       "xg_last_4_games                     float64\n",
       "poss_last_4_games                   float64\n",
       "opponent_sh_last_4_games            float64\n",
       "opponent_sot_last_4_games           float64\n",
       "opponent_dist_last_4_games          float64\n",
       "opponent_fk_last_4_games            float64\n",
       "opponent_pk_last_4_games            float64\n",
       "opponent_pkatt_last_4_games         float64\n",
       "opponent_xg_last_4_games            float64\n",
       "opponent_poss_last_4_games          float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Convert the 'date' column to datetime format\n",
    "df['date'] = pd.to_datetime(df['date'], format='%d.%m.%Y')\n",
    "\n",
    "# Combine 'date' and 'time' columns into a single datetime feature\n",
    "df['datetime'] = pd.to_datetime(df['date'].astype(str) + ' ' + df['time'])\n",
    "\n",
    "# Drop the 'time' column if not needed anymore\n",
    "df = df.drop(columns=['time'])\n",
    "# Making new column 'Hour' \n",
    "df['hour'] = df['datetime'].dt.hour\n",
    "\n",
    "# Convert categorical columns to category dtype for memory efficiency\n",
    "categorical_columns = ['comp', 'round', 'day', 'venue', 'result', 'captain', 'opponent_captain',\n",
    "                       'home_team_formation', 'away_team_formation', 'referee']\n",
    "\n",
    "df[categorical_columns] = df[categorical_columns].astype('category')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    04.03.2003\n",
       "1       4-2-3-1\n",
       "2    05.03.2002\n",
       "Name: home_team_formation, dtype: category\n",
       "Categories (19, object): ['03.04.2003', '03.05.2002', '04.03.2003', '04.04.2002', ..., '4-2-3-1', '4-3-1-2', '4-3-2-1', '4-4-1-1']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['home_team_formation'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_team_formation</th>\n",
       "      <th>away_team_formation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4-3-3</td>\n",
       "      <td>4-2-3-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4-2-3-1</td>\n",
       "      <td>4-2-3-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5-3-2</td>\n",
       "      <td>4-2-3-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4-1-4-1</td>\n",
       "      <td>4-3-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4-4-2</td>\n",
       "      <td>3-4-3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  home_team_formation away_team_formation\n",
       "0               4-3-3             4-2-3-1\n",
       "1             4-2-3-1             4-2-3-1\n",
       "2               5-3-2             4-2-3-1\n",
       "3             4-1-4-1               4-3-3\n",
       "4               4-4-2               3-4-3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Function to fix date-like strings back into football formations\n",
    "def fix_formation(entry):\n",
    "    # Check if the entry is a date-like format (xx.xx.xxxx)\n",
    "    if re.match(r'^\\d{2}\\.\\d{2}\\.\\d{4}$', str(entry)):\n",
    "        # Extract relevant digits\n",
    "        first_digit = int(entry[:2].lstrip('0'))  # First formation number (before the first dot)\n",
    "        second_digit = int(entry[3:5].lstrip('0'))  # Second formation number (after the first dot)\n",
    "        third_digit = int(entry[-1])   # Third formation number\n",
    "\n",
    "        # Return the corrected formation in the form of x-x-x\n",
    "        return f\"{first_digit}-{second_digit}-{third_digit}\"\n",
    "    \n",
    "    # Return the original entry if it's not a date-like string\n",
    "    return entry\n",
    "\n",
    "# Apply the function to fix 'home_team_formation' and 'away_team_formation'\n",
    "df['home_team_formation'] = df['home_team_formation'].apply(fix_formation)\n",
    "df['away_team_formation'] = df['away_team_formation'].apply(fix_formation)\n",
    "\n",
    "# Check the cleaned columns\n",
    "df[['home_team_formation', 'away_team_formation']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1260 entries, 0 to 1259\n",
      "Data columns (total 73 columns):\n",
      " #   Column                            Non-Null Count  Dtype         \n",
      "---  ------                            --------------  -----         \n",
      " 0   date                              1260 non-null   datetime64[ns]\n",
      " 1   comp                              1260 non-null   category      \n",
      " 2   round                             1260 non-null   category      \n",
      " 3   day                               1260 non-null   category      \n",
      " 4   venue                             1260 non-null   category      \n",
      " 5   result                            1260 non-null   category      \n",
      " 6   gf                                1260 non-null   int64         \n",
      " 7   ga                                1260 non-null   int64         \n",
      " 8   xg                                1259 non-null   float64       \n",
      " 9   xga                               1259 non-null   float64       \n",
      " 10  poss                              1260 non-null   int64         \n",
      " 11  opponent_gf                       1260 non-null   int64         \n",
      " 12  opponent_ga                       1260 non-null   int64         \n",
      " 13  opponent_xg                       1259 non-null   float64       \n",
      " 14  opponent_xga                      1259 non-null   float64       \n",
      " 15  opponent_poss                     1260 non-null   int64         \n",
      " 16  attendance                        1260 non-null   int64         \n",
      " 17  captain                           1260 non-null   category      \n",
      " 18  opponent_captain                  1260 non-null   category      \n",
      " 19  home_team_formation               1260 non-null   category      \n",
      " 20  away_team_formation               1260 non-null   category      \n",
      " 21  referee                           1251 non-null   category      \n",
      " 22  sh                                1260 non-null   int64         \n",
      " 23  sot                               1260 non-null   int64         \n",
      " 24  dist                              1257 non-null   float64       \n",
      " 25  fk                                1259 non-null   float64       \n",
      " 26  pk                                1260 non-null   int64         \n",
      " 27  pkatt                             1260 non-null   int64         \n",
      " 28  opponent_sh                       1260 non-null   int64         \n",
      " 29  opponent_sot                      1260 non-null   int64         \n",
      " 30  opponent_dist                     1259 non-null   float64       \n",
      " 31  opponent_fk                       1259 non-null   float64       \n",
      " 32  opponent_pk                       1260 non-null   int64         \n",
      " 33  opponent_pkatt                    1260 non-null   int64         \n",
      " 34  season                            1260 non-null   int64         \n",
      " 35  team                              1260 non-null   object        \n",
      " 36  opponent                          1260 non-null   object        \n",
      " 37  team_salary                       1260 non-null   int64         \n",
      " 38  opponent_team_salary              1260 non-null   int64         \n",
      " 39  gf_last_4_games                   1260 non-null   float64       \n",
      " 40  ga_last_4_games                   1260 non-null   float64       \n",
      " 41  xga_last_4_games                  1260 non-null   float64       \n",
      " 42  avg_points_last_4_games           1260 non-null   float64       \n",
      " 43  opponent_gf_last_4_games          1260 non-null   float64       \n",
      " 44  opponent_ga_last_4_games          1260 non-null   float64       \n",
      " 45  opponent_xga_last_4_games         1260 non-null   float64       \n",
      " 46  opponent_avg_points_last_4_games  1260 non-null   float64       \n",
      " 47  team_overall                      1260 non-null   int64         \n",
      " 48  team_attack                       1260 non-null   int64         \n",
      " 49  team_midfield                     1260 non-null   int64         \n",
      " 50  team_defense                      1260 non-null   int64         \n",
      " 51  opponent_overall                  1260 non-null   int64         \n",
      " 52  opponent_attack                   1260 non-null   int64         \n",
      " 53  opponent_midfield                 1260 non-null   int64         \n",
      " 54  opponent_defense                  1260 non-null   int64         \n",
      " 55  sh_last_4_games                   1260 non-null   float64       \n",
      " 56  sot_last_4_games                  1260 non-null   float64       \n",
      " 57  dist_last_4_games                 1260 non-null   float64       \n",
      " 58  fk_last_4_games                   1260 non-null   float64       \n",
      " 59  pk_last_4_games                   1260 non-null   float64       \n",
      " 60  pkatt_last_4_games                1260 non-null   float64       \n",
      " 61  xg_last_4_games                   1260 non-null   float64       \n",
      " 62  poss_last_4_games                 1260 non-null   float64       \n",
      " 63  opponent_sh_last_4_games          1260 non-null   float64       \n",
      " 64  opponent_sot_last_4_games         1260 non-null   float64       \n",
      " 65  opponent_dist_last_4_games        1260 non-null   float64       \n",
      " 66  opponent_fk_last_4_games          1260 non-null   float64       \n",
      " 67  opponent_pk_last_4_games          1260 non-null   float64       \n",
      " 68  opponent_pkatt_last_4_games       1260 non-null   float64       \n",
      " 69  opponent_xg_last_4_games          1260 non-null   float64       \n",
      " 70  opponent_poss_last_4_games        1260 non-null   float64       \n",
      " 71  datetime                          1260 non-null   datetime64[ns]\n",
      " 72  hour                              1260 non-null   int32         \n",
      "dtypes: category(10), datetime64[ns](2), float64(32), int32(1), int64(26), object(2)\n",
      "memory usage: 642.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Building initial model\n",
    "Without imputation, and with just encoding the target first to W/L/D  and then W/L&D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.0 First lets impute few missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xg               1\n",
       "xga              1\n",
       "opponent_xg      1\n",
       "opponent_xga     1\n",
       "referee          9\n",
       "dist             3\n",
       "fk               1\n",
       "opponent_dist    1\n",
       "opponent_fk      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values in the dataset\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# Filter to show only columns with missing values\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "\n",
    "# Display the columns with missing values and their count\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are only few will use simple imputer and dont bother much about them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date                                0\n",
      "comp                                0\n",
      "round                               0\n",
      "day                                 0\n",
      "venue                               0\n",
      "result                              0\n",
      "gf                                  0\n",
      "ga                                  0\n",
      "xg                                  0\n",
      "xga                                 0\n",
      "poss                                0\n",
      "opponent_gf                         0\n",
      "opponent_ga                         0\n",
      "opponent_xg                         0\n",
      "opponent_xga                        0\n",
      "opponent_poss                       0\n",
      "attendance                          0\n",
      "captain                             0\n",
      "opponent_captain                    0\n",
      "home_team_formation                 0\n",
      "away_team_formation                 0\n",
      "referee                             0\n",
      "sh                                  0\n",
      "sot                                 0\n",
      "dist                                0\n",
      "fk                                  0\n",
      "pk                                  0\n",
      "pkatt                               0\n",
      "opponent_sh                         0\n",
      "opponent_sot                        0\n",
      "opponent_dist                       0\n",
      "opponent_fk                         0\n",
      "opponent_pk                         0\n",
      "opponent_pkatt                      0\n",
      "season                              0\n",
      "team                                0\n",
      "opponent                            0\n",
      "team_salary                         0\n",
      "opponent_team_salary                0\n",
      "gf_last_4_games                     0\n",
      "ga_last_4_games                     0\n",
      "xga_last_4_games                    0\n",
      "avg_points_last_4_games             0\n",
      "opponent_gf_last_4_games            0\n",
      "opponent_ga_last_4_games            0\n",
      "opponent_xga_last_4_games           0\n",
      "opponent_avg_points_last_4_games    0\n",
      "team_overall                        0\n",
      "team_attack                         0\n",
      "team_midfield                       0\n",
      "team_defense                        0\n",
      "opponent_overall                    0\n",
      "opponent_attack                     0\n",
      "opponent_midfield                   0\n",
      "opponent_defense                    0\n",
      "sh_last_4_games                     0\n",
      "sot_last_4_games                    0\n",
      "dist_last_4_games                   0\n",
      "fk_last_4_games                     0\n",
      "pk_last_4_games                     0\n",
      "pkatt_last_4_games                  0\n",
      "xg_last_4_games                     0\n",
      "poss_last_4_games                   0\n",
      "opponent_sh_last_4_games            0\n",
      "opponent_sot_last_4_games           0\n",
      "opponent_dist_last_4_games          0\n",
      "opponent_fk_last_4_games            0\n",
      "opponent_pk_last_4_games            0\n",
      "opponent_pkatt_last_4_games         0\n",
      "opponent_xg_last_4_games            0\n",
      "opponent_poss_last_4_games          0\n",
      "datetime                            0\n",
      "hour                                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Impute missing values for numerical columns using the mean\n",
    "numerical_columns = ['xg', 'xga', 'opponent_xg', 'opponent_xga', 'dist', 'fk', 'opponent_dist', 'opponent_fk']\n",
    "num_imputer = SimpleImputer(strategy='mean')\n",
    "df[numerical_columns] = num_imputer.fit_transform(df[numerical_columns])\n",
    "\n",
    "# Impute missing values for categorical columns using the most frequent value\n",
    "categorical_columns = ['referee']\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "df[categorical_columns] = cat_imputer.fit_transform(df[categorical_columns])\n",
    "\n",
    "# Check if missing values are handled\n",
    "missing_values_after = df.isnull().sum()\n",
    "print(missing_values_after)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Lets see how model predicts if he got 3 target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5025125628140703"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=66, min_samples_split=10, random_state=42)\n",
    "\n",
    "# Encode the result column into numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "df['result_encoded'] = label_encoder.fit_transform(df['result'])\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "train = df[df[\"date\"] < '2024-01-01']\n",
    "test = df[df[\"date\"] > '2024-01-01']\n",
    "\n",
    "# Update the list of numerical predictors\n",
    "predictors = [\n",
    "    \"team_overall\", \"team_attack\", \"team_midfield\", \"team_defense\", \n",
    "    \"opponent_overall\", \"opponent_attack\", \"opponent_midfield\", \"opponent_defense\",\n",
    "    \"gf_last_4_games\", \"ga_last_4_games\", \"xg_last_4_games\", \"xga_last_4_games\", \n",
    "    \"avg_points_last_4_games\", \"sh_last_4_games\", \"sot_last_4_games\", \"poss_last_4_games\", \n",
    "    \"opponent_gf_last_4_games\", \"opponent_ga_last_4_games\", \"opponent_xga_last_4_games\", \n",
    "    \"opponent_avg_points_last_4_games\", \"team_salary\", \"opponent_team_salary\", \"hour\"\n",
    "]\n",
    "\n",
    "# Fit the model on the training set using 'result_encoded' as the target\n",
    "rf.fit(train[predictors], train['result_encoded'])\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = rf.predict(test[predictors])\n",
    "\n",
    "accuracy = accuracy_score(test[\"result_encoded\"], predictions)\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[63  4 13]\n",
      " [37  6 11]\n",
      " [29  5 31]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           W       0.49      0.79      0.60        80\n",
      "           D       0.40      0.11      0.17        54\n",
      "           L       0.56      0.48      0.52        65\n",
      "\n",
      "    accuracy                           0.50       199\n",
      "   macro avg       0.48      0.46      0.43       199\n",
      "weighted avg       0.49      0.50      0.46       199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decoding predictions back to W/D/L for better interpretation (I just wanted to test that and see how it works)\n",
    "predictions_decoded = label_encoder.inverse_transform(predictions)\n",
    "actual_results_decoded = label_encoder.inverse_transform(test['result_encoded'])\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(actual_results_decoded, predictions_decoded, labels=['W', 'D', 'L'])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Classification report (precision, recall, F1-score)\n",
    "class_report = classification_report(actual_results_decoded, predictions_decoded, labels=['W', 'D', 'L'])\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Now only when we trying to predict the Win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6532663316582915\n",
      "Confusion Matrix:\n",
      "[[82 37]\n",
      " [32 48]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.69      0.70       119\n",
      "           1       0.56      0.60      0.58        80\n",
      "\n",
      "    accuracy                           0.65       199\n",
      "   macro avg       0.64      0.64      0.64       199\n",
      "weighted avg       0.66      0.65      0.65       199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert 'result' to binary: 1 for Win, 0 for Lose/Draw\n",
    "df['win_binary'] = df['result'].apply(lambda x: 1 if x == 'W' else 0)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "train = df[df[\"date\"] < '2024-01-01']\n",
    "test = df[df[\"date\"] > '2024-01-01']\n",
    "\n",
    "# List of predictors (same as before, using numerical features)\n",
    "predictors = [\n",
    "    \"team_overall\", \"team_attack\", \"team_midfield\", \"team_defense\", \n",
    "    \"opponent_overall\", \"opponent_attack\", \"opponent_midfield\", \"opponent_defense\",\n",
    "    \"gf_last_4_games\", \"ga_last_4_games\", \"xg_last_4_games\", \"xga_last_4_games\", \n",
    "    \"avg_points_last_4_games\", \"sh_last_4_games\", \"sot_last_4_games\", \"poss_last_4_games\", \n",
    "    \"opponent_gf_last_4_games\", \"opponent_ga_last_4_games\", \"opponent_xga_last_4_games\", \n",
    "    \"opponent_avg_points_last_4_games\", \"team_salary\", \"opponent_team_salary\", \"hour\"\n",
    "]\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf = RandomForestClassifier(n_estimators=66, min_samples_split=10, random_state=42)\n",
    "\n",
    "# Fit the model on the training set with the new binary target\n",
    "rf.fit(train[predictors], train['win_binary'])\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = rf.predict(test[predictors])\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(test['win_binary'], predictions)\n",
    "conf_matrix = confusion_matrix(test['win_binary'], predictions)\n",
    "class_report = classification_report(test['win_binary'], predictions)\n",
    "\n",
    "# Display results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preparing the pipeline with encoding for Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numerical and categorical columns\n",
    "numerical_features = [\"team_overall\", \"team_attack\", \"team_midfield\", \"team_defense\", \n",
    "                        \"opponent_overall\", \"opponent_attack\", \"opponent_midfield\", \"opponent_defense\",\n",
    "                        \"gf_last_4_games\", \"ga_last_4_games\", \"xg_last_4_games\", \"xga_last_4_games\", \n",
    "                        \"avg_points_last_4_games\", \"sh_last_4_games\", \"sot_last_4_games\", \"poss_last_4_games\", \n",
    "                        \"opponent_gf_last_4_games\", \"opponent_ga_last_4_games\", \"opponent_xga_last_4_games\", \n",
    "                        \"opponent_avg_points_last_4_games\", \"team_salary\", \"opponent_team_salary\", \"hour\"]\n",
    "\n",
    "categorical_features = [\"venue\", \"day\", \"home_team_formation\", \"away_team_formation\", \"referee\"]\n",
    "\n",
    "# Define the preprocessing steps for numerical and categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='mean')),  # Impute missing values for numerical features\n",
    "                ('scaler', StandardScaler())  # Scale numerical features\n",
    "            ]), numerical_features),\n",
    "            \n",
    "            ('cat', Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing values for categorical features\n",
    "                ('encoder', OneHotEncoder(handle_unknown='ignore'))  # Encode categorical features\n",
    "            ]), categorical_features)\n",
    "        ])\n",
    "\n",
    "# Split the dataset based on date\n",
    "train = df[df[\"date\"] < '2023-09-01']\n",
    "test = df[df[\"date\"] >= '2023-09-01']\n",
    "\n",
    "# Extract the features (X) and target (y)\n",
    "X_train = train[numerical_features + categorical_features]\n",
    "y_train = train['result_encoded']\n",
    "X_test = test[numerical_features + categorical_features]\n",
    "y_test = test['result_encoded']\n",
    "\n",
    "# Pipeline ready for model integration\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', None)  # Placeholder for the classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Testing Models (All parameters were little bit tuned before so its not the whole procces and i focused on time constrain of my project and capability of my PC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>comp</th>\n",
       "      <th>round</th>\n",
       "      <th>day</th>\n",
       "      <th>venue</th>\n",
       "      <th>result</th>\n",
       "      <th>gf</th>\n",
       "      <th>ga</th>\n",
       "      <th>xg</th>\n",
       "      <th>xga</th>\n",
       "      <th>...</th>\n",
       "      <th>opponent_dist_last_4_games</th>\n",
       "      <th>opponent_fk_last_4_games</th>\n",
       "      <th>opponent_pk_last_4_games</th>\n",
       "      <th>opponent_pkatt_last_4_games</th>\n",
       "      <th>opponent_xg_last_4_games</th>\n",
       "      <th>opponent_poss_last_4_games</th>\n",
       "      <th>datetime</th>\n",
       "      <th>hour</th>\n",
       "      <th>result_encoded</th>\n",
       "      <th>win_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-09-26</td>\n",
       "      <td>Bundesliga</td>\n",
       "      <td>Matchweek 2</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Home</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>...</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>2020-09-26 15:30:00</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10-17</td>\n",
       "      <td>Bundesliga</td>\n",
       "      <td>Matchweek 4</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Home</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>...</td>\n",
       "      <td>16.966667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.966667</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>2020-10-17 18:30:00</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-10-31</td>\n",
       "      <td>Bundesliga</td>\n",
       "      <td>Matchweek 6</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Home</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>...</td>\n",
       "      <td>16.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.925000</td>\n",
       "      <td>68.500000</td>\n",
       "      <td>2020-10-31 15:30:00</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-11-21</td>\n",
       "      <td>Bundesliga</td>\n",
       "      <td>Matchweek 8</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Home</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>...</td>\n",
       "      <td>19.775000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.350000</td>\n",
       "      <td>61.500000</td>\n",
       "      <td>2020-11-21 15:30:00</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-12-05</td>\n",
       "      <td>Bundesliga</td>\n",
       "      <td>Matchweek 10</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Home</td>\n",
       "      <td>W</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>...</td>\n",
       "      <td>17.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>2020-12-05 15:30:00</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date        comp         round  day venue result  gf  ga   xg  xga  \\\n",
       "0 2020-09-26  Bundesliga   Matchweek 2  Sat  Home      W   1   0  0.2  1.4   \n",
       "1 2020-10-17  Bundesliga   Matchweek 4  Sat  Home      L   1   4  1.4  3.1   \n",
       "2 2020-10-31  Bundesliga   Matchweek 6  Sat  Home      L   0   2  0.3  2.4   \n",
       "3 2020-11-21  Bundesliga   Matchweek 8  Sat  Home      L   1   2  0.0  1.2   \n",
       "4 2020-12-05  Bundesliga  Matchweek 10  Sat  Home      W   2   1  1.2  2.8   \n",
       "\n",
       "   ...  opponent_dist_last_4_games  opponent_fk_last_4_games  \\\n",
       "0  ...                   12.000000                  0.000000   \n",
       "1  ...                   16.966667                  1.333333   \n",
       "2  ...                   16.200000                  0.500000   \n",
       "3  ...                   19.775000                  0.000000   \n",
       "4  ...                   17.250000                  0.250000   \n",
       "\n",
       "   opponent_pk_last_4_games  opponent_pkatt_last_4_games  \\\n",
       "0                  0.000000                     0.000000   \n",
       "1                  0.666667                     0.666667   \n",
       "2                  0.000000                     0.000000   \n",
       "3                  0.250000                     0.250000   \n",
       "4                  0.500000                     0.500000   \n",
       "\n",
       "   opponent_xg_last_4_games  opponent_poss_last_4_games            datetime  \\\n",
       "0                  2.700000                   49.000000 2020-09-26 15:30:00   \n",
       "1                  2.966667                   66.666667 2020-10-17 18:30:00   \n",
       "2                  1.925000                   68.500000 2020-10-31 15:30:00   \n",
       "3                  1.350000                   61.500000 2020-11-21 15:30:00   \n",
       "4                  2.300000                   37.000000 2020-12-05 15:30:00   \n",
       "\n",
       "  hour result_encoded win_binary  \n",
       "0   15              2          1  \n",
       "1   18              1          0  \n",
       "2   15              1          0  \n",
       "3   15              1          0  \n",
       "4   15              2          1  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters from GridSearchCV: {'classifier__colsample_bytree': 0.7, 'classifier__gamma': 0.3, 'classifier__learning_rate': 0.01, 'classifier__max_depth': 3, 'classifier__n_estimators': 100, 'classifier__subsample': 0.7}\n",
      "Best score from GridSearchCV: 0.5021\n",
      "Test set accuracy: 0.5525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\czarn\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:158: UserWarning: [13:20:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\czarn\\AppData\\Local\\Temp\\ipykernel_6432\\1548089573.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best Score</th>\n",
       "      <th>Best Params</th>\n",
       "      <th>Win Accuracy</th>\n",
       "      <th>Draw Accuracy</th>\n",
       "      <th>Loss Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.502137</td>\n",
       "      <td>{'classifier__colsample_bytree': 0.7, 'classif...</td>\n",
       "      <td>0.864286</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.552469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model  Best Score                                        Best Params  \\\n",
       "0  XGBoost    0.502137  {'classifier__colsample_bytree': 0.7, 'classif...   \n",
       "\n",
       "   Win Accuracy  Draw Accuracy  Loss Accuracy  Test Accuracy  \n",
       "0      0.864286       0.047059       0.545455       0.552469  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Parameters\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100],  # Fix based on the best result\n",
    "    'classifier__learning_rate': [0.01, 0.02],  # Slightly explore around the best result\n",
    "    'classifier__max_depth': [3, 4, 5],  # Explore depths around the best result\n",
    "    'classifier__subsample': [0.7],  # Fix based on the best result\n",
    "    'classifier__colsample_bytree': [0.7], # Fix based on the best result  \n",
    "    'classifier__gamma': [0.3]  # Fix based on the best result\n",
    "}\n",
    "\n",
    "# Replace the classifier in the pipeline with XGBoost configured to use GPU\n",
    "pipeline.steps[-1] = ('classifier', XGBClassifier(device='cuda', n_jobs=-1))\n",
    "\n",
    "# Set up GridSearchCV with the updated parameter grid\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions on the test set\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Confusion matrix using the encoded values for Draw (0), Loss (1), Win (2)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred, labels=[0, 1, 2])\n",
    "\n",
    "# Calculate per-class accuracy (Draw, Loss, Win)\n",
    "per_class_accuracy = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n",
    "draw_accuracy = per_class_accuracy[0]  # Accuracy for 'Draw' (0)\n",
    "loss_accuracy = per_class_accuracy[1]  # Accuracy for 'Loss' (1)\n",
    "win_accuracy = per_class_accuracy[2]  # Accuracy for 'Win' (2)\n",
    "\n",
    "# Best parameters and score from GridSearchCV\n",
    "best_params_grid = grid_search.best_params_\n",
    "print(f\"Best parameters from GridSearchCV: {best_params_grid}\")\n",
    "print(f\"Best score from GridSearchCV: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_accuracy = grid_search.score(X_test, y_test)\n",
    "print(f\"Test set accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Store best results including accuracy for Win, Draw, Loss, and test accuracy\n",
    "results_df = pd.DataFrame(columns=[\"Model\", \"Best Score\", \"Best Params\", \"Win Accuracy\", \"Draw Accuracy\", \"Loss Accuracy\", \"Test Accuracy\"])\n",
    "\n",
    "# Use pd.concat instead of append\n",
    "new_row = pd.DataFrame({\n",
    "    \"Model\": [\"XGBoost\"],\n",
    "    \"Best Score\": [grid_search.best_score_],\n",
    "    \"Best Params\": [best_params_grid],\n",
    "    \"Win Accuracy\": [win_accuracy],\n",
    "    \"Draw Accuracy\": [draw_accuracy],\n",
    "    \"Loss Accuracy\": [loss_accuracy],\n",
    "    \"Test Accuracy\": [test_accuracy]\n",
    "})\n",
    "\n",
    "# Concatenate the new row with the results DataFrame\n",
    "results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "# Save the results to a CSV\n",
    "results_df.to_csv(\"xgboost_tuning_results_with_accuracy.csv\", index=False)\n",
    "\n",
    "# Display the final results DataFrame\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im having low draw accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters from Random Forest GridSearchCV: {'classifier__bootstrap': True, 'classifier__max_depth': 10, 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 300}\n",
      "Best score from Random Forest GridSearchCV: 0.5064\n",
      "Test set accuracy for Random Forest: 0.5556\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best Score</th>\n",
       "      <th>Best Params</th>\n",
       "      <th>Win Accuracy</th>\n",
       "      <th>Draw Accuracy</th>\n",
       "      <th>Loss Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.502137</td>\n",
       "      <td>{'classifier__colsample_bytree': 0.7, 'classif...</td>\n",
       "      <td>0.864286</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.552469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.506410</td>\n",
       "      <td>{'classifier__bootstrap': True, 'classifier__m...</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model  Best Score  \\\n",
       "0       XGBoost    0.502137   \n",
       "1  RandomForest    0.506410   \n",
       "\n",
       "                                         Best Params  Win Accuracy  \\\n",
       "0  {'classifier__colsample_bytree': 0.7, 'classif...      0.864286   \n",
       "1  {'classifier__bootstrap': True, 'classifier__m...      0.885714   \n",
       "\n",
       "   Draw Accuracy  Loss Accuracy  Test Accuracy  \n",
       "0       0.047059       0.545455       0.552469  \n",
       "1       0.023529       0.545455       0.555556  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "# Define the broad parameter grid for Random Forest\n",
    "param_grid_rf = {\n",
    "    'classifier__n_estimators': [100, 200, 300],  \n",
    "    'classifier__max_depth': [10, 20, None],  \n",
    "    'classifier__min_samples_split': [2, 5, 10],  \n",
    "    'classifier__min_samples_leaf': [1, 2, 4],  \n",
    "    'classifier__bootstrap': [True, False] \n",
    "}\n",
    "\n",
    "# Replace the classifier in the pipeline with Random Forest\n",
    "pipeline.steps[-1] = ('classifier', RandomForestClassifier(random_state=42, n_jobs=-1))\n",
    "\n",
    "# Set up GridSearchCV for Random Forest\n",
    "grid_search_rf = GridSearchCV(pipeline, param_grid_rf, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV model for Random Forest\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions on the test set for Random Forest\n",
    "y_pred_rf = grid_search_rf.predict(X_test)\n",
    "\n",
    "# Confusion matrix using the encoded values for Draw (0), Loss (1), Win (2)\n",
    "conf_matrix_rf = confusion_matrix(y_test, y_pred_rf, labels=[0, 1, 2])\n",
    "\n",
    "# Calculate per-class accuracy (Draw, Loss, Win)\n",
    "per_class_accuracy_rf = conf_matrix_rf.diagonal() / conf_matrix_rf.sum(axis=1)\n",
    "draw_accuracy_rf = per_class_accuracy_rf[0]  # Accuracy for 'Draw' (0)\n",
    "loss_accuracy_rf = per_class_accuracy_rf[1]  # Accuracy for 'Loss' (1)\n",
    "win_accuracy_rf = per_class_accuracy_rf[2]  # Accuracy for 'Win' (2)\n",
    "\n",
    "# Best parameters and score from GridSearchCV for Random Forest\n",
    "best_params_rf = grid_search_rf.best_params_\n",
    "print(f\"Best parameters from Random Forest GridSearchCV: {best_params_rf}\")\n",
    "print(f\"Best score from Random Forest GridSearchCV: {grid_search_rf.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_accuracy_rf = grid_search_rf.score(X_test, y_test)\n",
    "print(f\"Test set accuracy for Random Forest: {test_accuracy_rf:.4f}\")\n",
    "\n",
    "# Append Random Forest results to the existing results_df\n",
    "new_row_rf = pd.DataFrame({\n",
    "    \"Model\": [\"RandomForest\"],\n",
    "    \"Best Score\": [grid_search_rf.best_score_],\n",
    "    \"Best Params\": [best_params_rf],\n",
    "    \"Win Accuracy\": [win_accuracy_rf],\n",
    "    \"Draw Accuracy\": [draw_accuracy_rf],\n",
    "    \"Loss Accuracy\": [loss_accuracy_rf],\n",
    "    \"Test Accuracy\": [test_accuracy_rf]\n",
    "})\n",
    "\n",
    "# Concatenate the new row with the existing results DataFrame\n",
    "results_df = pd.concat([results_df, new_row_rf], ignore_index=True)\n",
    "\n",
    "# Save the updated results to a CSV\n",
    "results_df.to_csv(\"tuning_results_with_accuracy.csv\", index=False)\n",
    "\n",
    "# Display the final results DataFrame with Random Forest results included\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since i found out that models struggle with predicting draws i decided to investigate it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Why Draws Are Hard to Predict: (I elaborate a little bit on that on my presentation)\n",
    "\n",
    "1. **Low Frequency**:\n",
    "   - Draws occur much less frequently than wins and losses, making it difficult for models to learn patterns associated with draws. In football leagues, draws typically represent only around 25-27% of outcomes. This class imbalance biases models toward predicting wins or losses.\n",
    "\n",
    "2. **Unpredictable Factors**:\n",
    "   - Draws are often the result of unpredictable factors such as team tactics, missed opportunities, or random events during the game. These small, nuanced details are hard for models to capture effectively, as draws are influenced by both defensive and offensive strategies.\n",
    "\n",
    "3. **Model Limitations**:\n",
    "   - Traditional machine learning models, as well as statistical approaches, have struggled to predict draws accurately. They tend to focus on more distinct patterns related to wins and losses, resulting in lower accuracy for draws. The presence of multiple potential outcomes (win, draw, loss) further complicates predictions.\n",
    "\n",
    "### Why Shift to **Win/Not Win** Predictions:\n",
    "\n",
    "1. **Simplified Problem**:\n",
    "   - By combining draws and losses into a single class (Not Win), the model's task becomes simpler: it only needs to predict whether a team wins or doesn’t win. This removes the complexity of distinguishing between draws and losses, leading to better predictive performance.\n",
    "\n",
    "2. **Addressing Class Imbalance**:\n",
    "   - Grouping draws with losses creates a more balanced dataset, reducing the issue of class imbalance. This allows the model to learn patterns related to both outcomes more effectively, without being skewed by the lower occurrence of draws.\n",
    "\n",
    "3. **Improved Accuracy**:\n",
    "   - Focusing on Win/Not Win predictions enables the model to provide clearer and more actionable insights, as predicting wins is often the key outcome in real-world scenarios (e.g., betting or match strategy). The simplified classification task leads to better overall accuracy.\n",
    "\n",
    "#### Conclusion:\n",
    "Due to the inherent difficulties of predicting draws and the advantages of a simplified binary classification task, shifting to **Win/Not Win** predictions will improve model performance and provide more meaningful predictions.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>comp</th>\n",
       "      <th>round</th>\n",
       "      <th>day</th>\n",
       "      <th>venue</th>\n",
       "      <th>result</th>\n",
       "      <th>gf</th>\n",
       "      <th>ga</th>\n",
       "      <th>xg</th>\n",
       "      <th>xga</th>\n",
       "      <th>...</th>\n",
       "      <th>opponent_dist_last_4_games</th>\n",
       "      <th>opponent_fk_last_4_games</th>\n",
       "      <th>opponent_pk_last_4_games</th>\n",
       "      <th>opponent_pkatt_last_4_games</th>\n",
       "      <th>opponent_xg_last_4_games</th>\n",
       "      <th>opponent_poss_last_4_games</th>\n",
       "      <th>datetime</th>\n",
       "      <th>hour</th>\n",
       "      <th>result_encoded</th>\n",
       "      <th>win_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-09-26</td>\n",
       "      <td>Bundesliga</td>\n",
       "      <td>Matchweek 2</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Home</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>...</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>2020-09-26 15:30:00</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10-17</td>\n",
       "      <td>Bundesliga</td>\n",
       "      <td>Matchweek 4</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Home</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>...</td>\n",
       "      <td>16.966667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.966667</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>2020-10-17 18:30:00</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-10-31</td>\n",
       "      <td>Bundesliga</td>\n",
       "      <td>Matchweek 6</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Home</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>...</td>\n",
       "      <td>16.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.925000</td>\n",
       "      <td>68.500000</td>\n",
       "      <td>2020-10-31 15:30:00</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-11-21</td>\n",
       "      <td>Bundesliga</td>\n",
       "      <td>Matchweek 8</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Home</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>...</td>\n",
       "      <td>19.775000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.350000</td>\n",
       "      <td>61.500000</td>\n",
       "      <td>2020-11-21 15:30:00</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-12-05</td>\n",
       "      <td>Bundesliga</td>\n",
       "      <td>Matchweek 10</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Home</td>\n",
       "      <td>W</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>...</td>\n",
       "      <td>17.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>2020-12-05 15:30:00</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-12-16</td>\n",
       "      <td>Bundesliga</td>\n",
       "      <td>Matchweek 12</td>\n",
       "      <td>Wed</td>\n",
       "      <td>Home</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>2020-12-16 20:30:00</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>Bundesliga</td>\n",
       "      <td>Matchweek 14</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Home</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>19.900000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>2021-01-02 15:30:00</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-01-10</td>\n",
       "      <td>Bundesliga</td>\n",
       "      <td>Matchweek 15</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Home</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>17.325000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>2021-01-10 18:00:00</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-01-20</td>\n",
       "      <td>Bundesliga</td>\n",
       "      <td>Matchweek 17</td>\n",
       "      <td>Wed</td>\n",
       "      <td>Home</td>\n",
       "      <td>W</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>...</td>\n",
       "      <td>15.775000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>53.500000</td>\n",
       "      <td>2021-01-20 20:30:00</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-01-23</td>\n",
       "      <td>Bundesliga</td>\n",
       "      <td>Matchweek 18</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Home</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>...</td>\n",
       "      <td>17.100000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.775000</td>\n",
       "      <td>55.500000</td>\n",
       "      <td>2021-01-23 15:30:00</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021-02-19</td>\n",
       "      <td>Bundesliga</td>\n",
       "      <td>Matchweek 22</td>\n",
       "      <td>Fri</td>\n",
       "      <td>Home</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>...</td>\n",
       "      <td>15.925000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.450000</td>\n",
       "      <td>47.750000</td>\n",
       "      <td>2021-02-19 20:30:00</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2021-03-07</td>\n",
       "      <td>Bundesliga</td>\n",
       "      <td>Matchweek 24</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Home</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>...</td>\n",
       "      <td>18.325000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>2021-03-07 18:00:00</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2021-03-10</td>\n",
       "      <td>Bundesliga</td>\n",
       "      <td>Matchweek 20</td>\n",
       "      <td>Wed</td>\n",
       "      <td>Home</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>...</td>\n",
       "      <td>17.275000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>2021-03-10 18:30:00</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2021-03-19</td>\n",
       "      <td>Bundesliga</td>\n",
       "      <td>Matchweek 26</td>\n",
       "      <td>Fri</td>\n",
       "      <td>Home</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>...</td>\n",
       "      <td>18.975000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>2021-03-19 20:30:00</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2021-04-09</td>\n",
       "      <td>Bundesliga</td>\n",
       "      <td>Matchweek 28</td>\n",
       "      <td>Fri</td>\n",
       "      <td>Home</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>18.550000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.150000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>2021-04-09 20:30:00</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        comp         round  day venue result  gf  ga   xg  xga  \\\n",
       "0  2020-09-26  Bundesliga   Matchweek 2  Sat  Home      W   1   0  0.2  1.4   \n",
       "1  2020-10-17  Bundesliga   Matchweek 4  Sat  Home      L   1   4  1.4  3.1   \n",
       "2  2020-10-31  Bundesliga   Matchweek 6  Sat  Home      L   0   2  0.3  2.4   \n",
       "3  2020-11-21  Bundesliga   Matchweek 8  Sat  Home      L   1   2  0.0  1.2   \n",
       "4  2020-12-05  Bundesliga  Matchweek 10  Sat  Home      W   2   1  1.2  2.8   \n",
       "5  2020-12-16  Bundesliga  Matchweek 12  Wed  Home      L   0   1  0.6  0.4   \n",
       "6  2021-01-02  Bundesliga  Matchweek 14  Sat  Home      L   0   1  0.9  2.5   \n",
       "7  2021-01-10  Bundesliga  Matchweek 15  Sun  Home      W   1   0  0.7  0.6   \n",
       "8  2021-01-20  Bundesliga  Matchweek 17  Wed  Home      W   3   0  1.8  1.4   \n",
       "9  2021-01-23  Bundesliga  Matchweek 18  Sat  Home      L   1   5  0.5  2.4   \n",
       "10 2021-02-19  Bundesliga  Matchweek 22  Fri  Home      L   0   3  0.6  1.5   \n",
       "11 2021-03-07  Bundesliga  Matchweek 24  Sun  Home      D   0   0  0.4  1.4   \n",
       "12 2021-03-10  Bundesliga  Matchweek 20  Wed  Home      L   0   2  3.1  1.6   \n",
       "13 2021-03-19  Bundesliga  Matchweek 26  Fri  Home      L   0   1  0.3  2.2   \n",
       "14 2021-04-09  Bundesliga  Matchweek 28  Fri  Home      W   1   0  1.3  0.4   \n",
       "\n",
       "    ...  opponent_dist_last_4_games  opponent_fk_last_4_games  \\\n",
       "0   ...                   12.000000                  0.000000   \n",
       "1   ...                   16.966667                  1.333333   \n",
       "2   ...                   16.200000                  0.500000   \n",
       "3   ...                   19.775000                  0.000000   \n",
       "4   ...                   17.250000                  0.250000   \n",
       "5   ...                   18.750000                  0.250000   \n",
       "6   ...                   19.900000                  0.750000   \n",
       "7   ...                   17.325000                  0.250000   \n",
       "8   ...                   15.775000                  0.000000   \n",
       "9   ...                   17.100000                  0.500000   \n",
       "10  ...                   15.925000                  0.000000   \n",
       "11  ...                   18.325000                  0.250000   \n",
       "12  ...                   17.275000                  0.500000   \n",
       "13  ...                   18.975000                  1.000000   \n",
       "14  ...                   18.550000                  0.750000   \n",
       "\n",
       "    opponent_pk_last_4_games  opponent_pkatt_last_4_games  \\\n",
       "0                   0.000000                     0.000000   \n",
       "1                   0.666667                     0.666667   \n",
       "2                   0.000000                     0.000000   \n",
       "3                   0.250000                     0.250000   \n",
       "4                   0.500000                     0.500000   \n",
       "5                   0.000000                     0.000000   \n",
       "6                   0.500000                     0.500000   \n",
       "7                   0.000000                     0.000000   \n",
       "8                   0.500000                     0.500000   \n",
       "9                   0.500000                     0.500000   \n",
       "10                  0.000000                     0.000000   \n",
       "11                  0.250000                     0.250000   \n",
       "12                  0.000000                     0.000000   \n",
       "13                  0.000000                     0.000000   \n",
       "14                  0.000000                     0.000000   \n",
       "\n",
       "    opponent_xg_last_4_games  opponent_poss_last_4_games            datetime  \\\n",
       "0                   2.700000                   49.000000 2020-09-26 15:30:00   \n",
       "1                   2.966667                   66.666667 2020-10-17 18:30:00   \n",
       "2                   1.925000                   68.500000 2020-10-31 15:30:00   \n",
       "3                   1.350000                   61.500000 2020-11-21 15:30:00   \n",
       "4                   2.300000                   37.000000 2020-12-05 15:30:00   \n",
       "5                   0.900000                   48.000000 2020-12-16 20:30:00   \n",
       "6                   1.625000                   56.000000 2021-01-02 15:30:00   \n",
       "7                   1.300000                   57.000000 2021-01-10 18:00:00   \n",
       "8                   1.900000                   53.500000 2021-01-20 20:30:00   \n",
       "9                   1.775000                   55.500000 2021-01-23 15:30:00   \n",
       "10                  1.450000                   47.750000 2021-02-19 20:30:00   \n",
       "11                  1.400000                   44.000000 2021-03-07 18:00:00   \n",
       "12                  0.725000                   40.000000 2021-03-10 18:30:00   \n",
       "13                  1.375000                   58.000000 2021-03-19 20:30:00   \n",
       "14                  1.150000                   51.000000 2021-04-09 20:30:00   \n",
       "\n",
       "   hour result_encoded win_binary  \n",
       "0    15              2          1  \n",
       "1    18              1          0  \n",
       "2    15              1          0  \n",
       "3    15              1          0  \n",
       "4    15              2          1  \n",
       "5    20              1          0  \n",
       "6    15              1          0  \n",
       "7    18              2          1  \n",
       "8    20              2          1  \n",
       "9    15              1          0  \n",
       "10   20              1          0  \n",
       "11   18              0          0  \n",
       "12   18              1          0  \n",
       "13   20              1          0  \n",
       "14   20              2          1  \n",
       "\n",
       "[15 rows x 75 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Testing Models just on binary classification Win/Not Win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract the features (X) and target (y) for binary classification\n",
    "X_train_binary = train[numerical_features + categorical_features]\n",
    "y_train_binary = train['win_binary']  # Ensure 'win_binary' column exists in your DataFrame\n",
    "X_test_binary = test[numerical_features + categorical_features]\n",
    "y_test_binary = test['win_binary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters from GridSearchCV (XGBoost): {'classifier__colsample_bytree': 0.8, 'classifier__gamma': 0, 'classifier__learning_rate': 0.01, 'classifier__max_depth': 6, 'classifier__min_child_weight': 3, 'classifier__n_estimators': 100, 'classifier__reg_alpha': 0, 'classifier__reg_lambda': 1, 'classifier__subsample': 0.8}\n",
      "Best score from GridSearchCV (XGBoost): 0.5834\n",
      "Test set accuracy (XGBoost): 0.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\czarn\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:158: UserWarning: [14:34:10] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best Score</th>\n",
       "      <th>Best Params</th>\n",
       "      <th>Win Accuracy</th>\n",
       "      <th>Loss Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost - Win/Loss</td>\n",
       "      <td>0.615349</td>\n",
       "      <td>{'classifier__colsample_bytree': 0.8, 'classif...</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.657609</td>\n",
       "      <td>0.651235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost - Win/Loss</td>\n",
       "      <td>0.583391</td>\n",
       "      <td>{'classifier__colsample_bytree': 0.8, 'classif...</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.679348</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  Best Score  \\\n",
       "0  XGBoost - Win/Loss    0.615349   \n",
       "1  XGBoost - Win/Loss    0.583391   \n",
       "\n",
       "                                         Best Params  Win Accuracy  \\\n",
       "0  {'classifier__colsample_bytree': 0.8, 'classif...      0.642857   \n",
       "1  {'classifier__colsample_bytree': 0.8, 'classif...      0.650000   \n",
       "\n",
       "   Loss Accuracy  Test Accuracy  \n",
       "0       0.657609       0.651235  \n",
       "1       0.679348       0.666667  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_xgb = {\n",
    "    'classifier__n_estimators': [100, 150],  # Number of trees\n",
    "    'classifier__max_depth': [3, 6],  # Maximum depth of trees\n",
    "    'classifier__learning_rate': [0.01, 0.1],  # Learning rate\n",
    "    'classifier__subsample': [0.8, 1.0],  # Subsample ratio\n",
    "    'classifier__colsample_bytree': [0.8, 1.0],  # Subsample ratio of columns for each tree\n",
    "    'classifier__gamma': [0, 0.1],  # Minimum loss reduction to make a split\n",
    "    'classifier__min_child_weight': [1, 3],  # Minimum sum of instance weight needed in a child\n",
    "    'classifier__reg_alpha': [0, 0.1],  # L1 regularization term\n",
    "    'classifier__reg_lambda': [0.1, 1],  # L2 regularization term\n",
    "    }\n",
    "\n",
    "\n",
    "# Replace the classifier in the pipeline with XGBoost\n",
    "pipeline.steps[-1] = ('classifier', xgb.XGBClassifier(\n",
    "    tree_method=\"hist\", \n",
    "    use_label_encoder=False, \n",
    "    eval_metric='logloss',\n",
    "    random_state=1, \n",
    "    scale_pos_weight=1.23  # Apply class weighting\n",
    "))\n",
    "\n",
    "# Set up GridSearchCV for XGBoost\n",
    "grid_search_xgb = GridSearchCV(pipeline, param_grid_xgb, cv=10, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the XGBoost model\n",
    "grid_search_xgb.fit(X_train_binary, y_train_binary)\n",
    "\n",
    "# Save the best model to a file using joblib\n",
    "joblib.dump(grid_search_xgb.best_estimator_, 'best_xgb_model.pkl')\n",
    "\n",
    "# Get predictions on the test set\n",
    "y_pred_xgb = grid_search_xgb.predict(X_test_binary)\n",
    "\n",
    "# Confusion matrix for binary classification (1 = Win, 0 = Loss)\n",
    "conf_matrix_xgb = confusion_matrix(y_test_binary, y_pred_xgb, labels=[0, 1])\n",
    "\n",
    "# Calculate accuracy for Win and Loss classes\n",
    "loss_accuracy_xgb = conf_matrix_xgb[0, 0] / conf_matrix_xgb[0].sum()  # Accuracy for 'Loss' (0)\n",
    "win_accuracy_xgb = conf_matrix_xgb[1, 1] / conf_matrix_xgb[1].sum()  # Accuracy for 'Win' (1)\n",
    "\n",
    "# Best parameters and score from GridSearchCV\n",
    "best_params_grid_xgb = grid_search_xgb.best_params_\n",
    "print(f\"Best parameters from GridSearchCV (XGBoost): {best_params_grid_xgb}\")\n",
    "print(f\"Best score from GridSearchCV (XGBoost): {grid_search_xgb.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate the XGBoost model on the test set\n",
    "test_accuracy_xgb = grid_search_xgb.score(X_test_binary, y_test_binary)\n",
    "print(f\"Test set accuracy (XGBoost): {test_accuracy_xgb:.4f}\")\n",
    "\n",
    "# Initialize results_df_win_loss if it doesn't exist\n",
    "if 'results_df_win_notwin' not in locals():\n",
    "    results_df_win_notwin = pd.DataFrame(columns=[\"Model\", \"Best Score\", \"Best Params\", \"Win Accuracy\", \"Loss Accuracy\", \"Test Accuracy\"])\n",
    "\n",
    "# Check if the current XGBoost test accuracy is better than the previous best for XGBoost\n",
    "if \"XGBoost - Win/Loss\" not in results_df_win_notwin[\"Model\"].values or test_accuracy_xgb > results_df_win_notwin[results_df_win_notwin[\"Model\"] == \"XGBoost - Win/Loss\"][\"Test Accuracy\"].values[0]:\n",
    "\n",
    "    # Append the XGBoost results to the existing results DataFrame\n",
    "    new_row_xgb = pd.DataFrame({\n",
    "        \"Model\": [\"XGBoost - Win/Loss\"],\n",
    "        \"Best Score\": [grid_search_xgb.best_score_],\n",
    "        \"Best Params\": [best_params_grid_xgb],\n",
    "        \"Win Accuracy\": [win_accuracy_xgb],\n",
    "        \"Loss Accuracy\": [loss_accuracy_xgb],\n",
    "        \"Test Accuracy\": [test_accuracy_xgb]\n",
    "    })\n",
    "\n",
    "    # Append the new row with XGBoost results to the existing DataFrame\n",
    "    results_df_win_notwin = pd.concat([results_df_win_notwin, new_row_xgb], ignore_index=True)\n",
    "\n",
    "    # Save the updated DataFrame to the CSV file\n",
    "    results_df_win_notwin.to_csv(\"win_notwin_tuning_results.csv\", index=False)\n",
    "\n",
    "# Display the updated results DataFrame\n",
    "results_df_win_notwin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters from GridSearchCV (Random Forest): {'classifier__bootstrap': True, 'classifier__max_depth': 20, 'classifier__max_features': 'log2', 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 100}\n",
      "Best score from GridSearchCV (Random Forest): 0.6410\n",
      "Test set accuracy (Random Forest): 0.6481\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best Score</th>\n",
       "      <th>Best Params</th>\n",
       "      <th>Win Accuracy</th>\n",
       "      <th>Loss Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost - Win/Loss</td>\n",
       "      <td>0.615349</td>\n",
       "      <td>{'classifier__colsample_bytree': 0.8, 'classif...</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.657609</td>\n",
       "      <td>0.651235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost - Win/Loss</td>\n",
       "      <td>0.583391</td>\n",
       "      <td>{'classifier__colsample_bytree': 0.8, 'classif...</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.679348</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest - Win/Loss</td>\n",
       "      <td>0.640983</td>\n",
       "      <td>{'classifier__bootstrap': True, 'classifier__m...</td>\n",
       "      <td>0.578571</td>\n",
       "      <td>0.701087</td>\n",
       "      <td>0.648148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model  Best Score  \\\n",
       "0        XGBoost - Win/Loss    0.615349   \n",
       "1        XGBoost - Win/Loss    0.583391   \n",
       "2  Random Forest - Win/Loss    0.640983   \n",
       "\n",
       "                                         Best Params  Win Accuracy  \\\n",
       "0  {'classifier__colsample_bytree': 0.8, 'classif...      0.642857   \n",
       "1  {'classifier__colsample_bytree': 0.8, 'classif...      0.650000   \n",
       "2  {'classifier__bootstrap': True, 'classifier__m...      0.578571   \n",
       "\n",
       "   Loss Accuracy  Test Accuracy  \n",
       "0       0.657609       0.651235  \n",
       "1       0.679348       0.666667  \n",
       "2       0.701087       0.648148  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a broader parameter grid for Random Forest\n",
    "param_grid_rf = {\n",
    "    'classifier__n_estimators': [100, 200, 300, 400],  # Number of trees\n",
    "    'classifier__max_depth': [10, 15, 20],  # Maximum depth of trees\n",
    "    'classifier__min_samples_split': [2, 5, 10],  # Minimum samples to split a node\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],  # Minimum samples required at a leaf node\n",
    "    'classifier__max_features': ['sqrt', 'log2'],  # Only valid options for max_features\n",
    "    'classifier__bootstrap': [True, False]  # Whether bootstrap samples are used\n",
    "}\n",
    "\n",
    "# Replace the classifier in the pipeline with RandomForestClassifier\n",
    "pipeline.steps[-1] = ('classifier', RandomForestClassifier(class_weight='balanced', n_jobs=-1, random_state=1))\n",
    "\n",
    "# Set up GridSearchCV for Random Forest\n",
    "grid_search_rf = GridSearchCV(pipeline, param_grid_rf, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the Random Forest model\n",
    "grid_search_rf.fit(X_train_binary, y_train_binary)\n",
    "\n",
    "# Save the best Random Forest model to a file using joblib\n",
    "joblib.dump(grid_search_rf.best_estimator_, 'best_rf_model.pkl')\n",
    "\n",
    "# Get predictions on the test set\n",
    "y_pred_rf = grid_search_rf.predict(X_test_binary)\n",
    "\n",
    "# Confusion matrix for binary classification (1 = Win, 0 = Loss)\n",
    "conf_matrix_rf = confusion_matrix(y_test_binary, y_pred_rf, labels=[0, 1])\n",
    "\n",
    "# Calculate accuracy for Win and Loss classes\n",
    "loss_accuracy_rf = conf_matrix_rf[0, 0] / conf_matrix_rf[0].sum()  # Accuracy for 'Loss' (0)\n",
    "win_accuracy_rf = conf_matrix_rf[1, 1] / conf_matrix_rf[1].sum()  # Accuracy for 'Win' (1)\n",
    "\n",
    "# Best parameters and score from GridSearchCV\n",
    "best_params_grid_rf = grid_search_rf.best_params_\n",
    "print(f\"Best parameters from GridSearchCV (Random Forest): {best_params_grid_rf}\")\n",
    "print(f\"Best score from GridSearchCV (Random Forest): {grid_search_rf.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate the Random Forest model on the test set\n",
    "test_accuracy_rf = grid_search_rf.score(X_test_binary, y_test_binary)\n",
    "print(f\"Test set accuracy (Random Forest): {test_accuracy_rf:.4f}\")\n",
    "\n",
    "# Check if the current Random Forest test accuracy is better than the previous best for Random Forest\n",
    "if \"Random Forest - Win/Loss\" not in results_df_win_notwin[\"Model\"].values or test_accuracy_rf > results_df_win_notwin[results_df_win_notwin[\"Model\"] == \"Random Forest - Win/Loss\"][\"Test Accuracy\"].values[0]:\n",
    "\n",
    "    # Append the Random Forest results to the existing results DataFrame\n",
    "    new_row_rf = pd.DataFrame({\n",
    "        \"Model\": [\"Random Forest - Win/Loss\"],\n",
    "        \"Best Score\": [grid_search_rf.best_score_],\n",
    "        \"Best Params\": [best_params_grid_rf],\n",
    "        \"Win Accuracy\": [win_accuracy_rf],\n",
    "        \"Loss Accuracy\": [loss_accuracy_rf],\n",
    "        \"Test Accuracy\": [test_accuracy_rf]\n",
    "    })\n",
    "\n",
    "    # Append the new row with Random Forest results to the existing DataFrame\n",
    "    results_df_win_notwin = pd.concat([results_df_win_notwin, new_row_rf], ignore_index=True)\n",
    "\n",
    "    # Save the updated DataFrame to the CSV file\n",
    "    results_df_win_notwin.to_csv(\"win_loss_tuning_results.csv\", index=False)\n",
    "\n",
    "# Display the updated results DataFrame\n",
    "results_df_win_notwin\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters from GridSearchCV (Logistic Regression): {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__l1_ratio': 0.1, 'classifier__max_iter': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}\n",
      "Best score from GridSearchCV (Logistic Regression): 0.6442\n",
      "Test set accuracy (Logistic Regression): 0.6790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\czarn\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\czarn\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best Score</th>\n",
       "      <th>Best Params</th>\n",
       "      <th>Win Accuracy</th>\n",
       "      <th>Loss Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost - Win/Loss</td>\n",
       "      <td>0.615349</td>\n",
       "      <td>{'classifier__colsample_bytree': 0.8, 'classif...</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.657609</td>\n",
       "      <td>0.651235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost - Win/Loss</td>\n",
       "      <td>0.583391</td>\n",
       "      <td>{'classifier__colsample_bytree': 0.8, 'classif...</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.679348</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest - Win/Loss</td>\n",
       "      <td>0.640983</td>\n",
       "      <td>{'classifier__bootstrap': True, 'classifier__m...</td>\n",
       "      <td>0.578571</td>\n",
       "      <td>0.701087</td>\n",
       "      <td>0.648148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression - Win/Loss</td>\n",
       "      <td>0.644166</td>\n",
       "      <td>{'classifier__C': 0.01, 'classifier__class_wei...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.679012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Model  Best Score  \\\n",
       "0              XGBoost - Win/Loss    0.615349   \n",
       "1              XGBoost - Win/Loss    0.583391   \n",
       "2        Random Forest - Win/Loss    0.640983   \n",
       "3  Logistic Regression - Win/Loss    0.644166   \n",
       "\n",
       "                                         Best Params  Win Accuracy  \\\n",
       "0  {'classifier__colsample_bytree': 0.8, 'classif...      0.642857   \n",
       "1  {'classifier__colsample_bytree': 0.8, 'classif...      0.650000   \n",
       "2  {'classifier__bootstrap': True, 'classifier__m...      0.578571   \n",
       "3  {'classifier__C': 0.01, 'classifier__class_wei...      0.600000   \n",
       "\n",
       "   Loss Accuracy  Test Accuracy  \n",
       "0       0.657609       0.651235  \n",
       "1       0.679348       0.666667  \n",
       "2       0.701087       0.648148  \n",
       "3       0.739130       0.679012  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "param_grid_lr = {\n",
    "    'classifier__C': [0.01],  \n",
    "    'classifier__penalty': ['l2'],\n",
    "    'classifier__solver': ['liblinear'],  \n",
    "    'classifier__max_iter': [100], \n",
    "    'classifier__l1_ratio': [0.1, 0.5, 0.9], \n",
    "    'classifier__class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "# Replace the classifier in the pipeline with LogisticRegression\n",
    "pipeline.steps[-1] = ('classifier', LogisticRegression(n_jobs=-1, random_state=1))\n",
    "\n",
    "# Set up GridSearchCV for Logistic Regression\n",
    "grid_search_lr = GridSearchCV(pipeline, param_grid_lr, cv=10, scoring='accuracy', n_jobs=-1, error_score='raise')\n",
    "\n",
    "# Fit the Logistic Regression model\n",
    "grid_search_lr.fit(X_train_binary, y_train_binary)\n",
    "\n",
    "# Save the best Logistic Regression model to a file using joblib\n",
    "joblib.dump(grid_search_lr.best_estimator_, 'best_lr_model.pkl')\n",
    "\n",
    "# Get predictions on the test set\n",
    "y_pred_lr = grid_search_lr.predict(X_test_binary)\n",
    "\n",
    "# Confusion matrix for binary classification (1 = Win, 0 = Loss)\n",
    "conf_matrix_lr = confusion_matrix(y_test_binary, y_pred_lr, labels=[0, 1])\n",
    "\n",
    "# Calculate accuracy for Win and Loss classes\n",
    "loss_accuracy_lr = conf_matrix_lr[0, 0] / conf_matrix_lr[0].sum()  # Accuracy for 'Loss' (0)\n",
    "win_accuracy_lr = conf_matrix_lr[1, 1] / conf_matrix_lr[1].sum()  # Accuracy for 'Win' (1)\n",
    "\n",
    "# Best parameters and score from GridSearchCV\n",
    "best_params_grid_lr = grid_search_lr.best_params_\n",
    "print(f\"Best parameters from GridSearchCV (Logistic Regression): {best_params_grid_lr}\")\n",
    "print(f\"Best score from GridSearchCV (Logistic Regression): {grid_search_lr.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate the Logistic Regression model on the test set\n",
    "test_accuracy_lr = grid_search_lr.score(X_test_binary, y_test_binary)\n",
    "print(f\"Test set accuracy (Logistic Regression): {test_accuracy_lr:.4f}\")\n",
    "\n",
    "# Check if the current Logistic Regression test accuracy is better than the previous best for Logistic Regression\n",
    "if \"Logistic Regression - Win/Loss\" not in results_df_win_notwin[\"Model\"].values or test_accuracy_lr > results_df_win_notwin[results_df_win_notwin[\"Model\"] == \"Logistic Regression - Win/Loss\"][\"Test Accuracy\"].values[0]:\n",
    "    \n",
    "    # Append the Logistic Regression results to the existing results DataFrame\n",
    "    new_row_lr = pd.DataFrame({\n",
    "        \"Model\": [\"Logistic Regression - Win/Loss\"],\n",
    "        \"Best Score\": [grid_search_lr.best_score_],\n",
    "        \"Best Params\": [best_params_grid_lr],\n",
    "        \"Win Accuracy\": [win_accuracy_lr],\n",
    "        \"Loss Accuracy\": [loss_accuracy_lr],\n",
    "        \"Test Accuracy\": [test_accuracy_lr]\n",
    "    })\n",
    "\n",
    "    # Append the new row with Logistic Regression results to the existing DataFrame\n",
    "    results_df_win_notwin = pd.concat([results_df_win_notwin, new_row_lr], ignore_index=True)\n",
    "\n",
    "    # Save the updated DataFrame to the CSV file\n",
    "    results_df_win_notwin.to_csv(\"win_loss_tuning_results.csv\", index=False)\n",
    "\n",
    "# Display the updated results DataFrame\n",
    "results_df_win_notwin\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 K-nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters from GridSearchCV (KNN): {'classifier__metric': 'manhattan', 'classifier__n_neighbors': 25, 'classifier__p': 1, 'classifier__weights': 'distance'}\n",
      "Best score from GridSearchCV (KNN): 0.6282\n",
      "Test set accuracy (KNN): 0.6389\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best Score</th>\n",
       "      <th>Best Params</th>\n",
       "      <th>Win Accuracy</th>\n",
       "      <th>Loss Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost - Win/Loss</td>\n",
       "      <td>0.615349</td>\n",
       "      <td>{'classifier__colsample_bytree': 0.8, 'classif...</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.657609</td>\n",
       "      <td>0.651235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost - Win/Loss</td>\n",
       "      <td>0.583391</td>\n",
       "      <td>{'classifier__colsample_bytree': 0.8, 'classif...</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.679348</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest - Win/Loss</td>\n",
       "      <td>0.640983</td>\n",
       "      <td>{'classifier__bootstrap': True, 'classifier__m...</td>\n",
       "      <td>0.578571</td>\n",
       "      <td>0.701087</td>\n",
       "      <td>0.648148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression - Win/Loss</td>\n",
       "      <td>0.644166</td>\n",
       "      <td>{'classifier__C': 0.01, 'classifier__class_wei...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.679012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbors - Win/Loss</td>\n",
       "      <td>0.628189</td>\n",
       "      <td>{'classifier__metric': 'manhattan', 'classifie...</td>\n",
       "      <td>0.564286</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.638889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Model  Best Score  \\\n",
       "0              XGBoost - Win/Loss    0.615349   \n",
       "1              XGBoost - Win/Loss    0.583391   \n",
       "2        Random Forest - Win/Loss    0.640983   \n",
       "3  Logistic Regression - Win/Loss    0.644166   \n",
       "4  K-Nearest Neighbors - Win/Loss    0.628189   \n",
       "\n",
       "                                         Best Params  Win Accuracy  \\\n",
       "0  {'classifier__colsample_bytree': 0.8, 'classif...      0.642857   \n",
       "1  {'classifier__colsample_bytree': 0.8, 'classif...      0.650000   \n",
       "2  {'classifier__bootstrap': True, 'classifier__m...      0.578571   \n",
       "3  {'classifier__C': 0.01, 'classifier__class_wei...      0.600000   \n",
       "4  {'classifier__metric': 'manhattan', 'classifie...      0.564286   \n",
       "\n",
       "   Loss Accuracy  Test Accuracy  \n",
       "0       0.657609       0.651235  \n",
       "1       0.679348       0.666667  \n",
       "2       0.701087       0.648148  \n",
       "3       0.739130       0.679012  \n",
       "4       0.695652       0.638889  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "param_grid_knn = {\n",
    "    'classifier__n_neighbors': [3, 5, 7, 9, 11, 15, 19, 25, 27],\n",
    "    'classifier__weights': ['uniform', 'distance'],\n",
    "    'classifier__metric': ['euclidean', 'manhattan'],  \n",
    "    'classifier__p': [1, 2]  \n",
    "}\n",
    "\n",
    "# Replace the classifier in the pipeline with KNeighborsClassifier\n",
    "pipeline.steps[-1] = ('classifier', KNeighborsClassifier(n_jobs=-1))\n",
    "\n",
    "# Set up GridSearchCV for K-Nearest Neighbors\n",
    "grid_search_knn = GridSearchCV(pipeline, param_grid_knn, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the KNN model\n",
    "grid_search_knn.fit(X_train_binary, y_train_binary)\n",
    "\n",
    "# Save the best KNN model to a file using joblib\n",
    "joblib.dump(grid_search_knn.best_estimator_, 'best_knn_model.pkl')\n",
    "\n",
    "# Get predictions on the test set\n",
    "y_pred_knn = grid_search_knn.predict(X_test_binary)\n",
    "\n",
    "# Confusion matrix for binary classification (1 = Win, 0 = Loss)\n",
    "conf_matrix_knn = confusion_matrix(y_test_binary, y_pred_knn, labels=[0, 1])\n",
    "\n",
    "# Calculate accuracy for Win and Loss classes\n",
    "loss_accuracy_knn = conf_matrix_knn[0, 0] / conf_matrix_knn[0].sum()  # Accuracy for 'Loss' (0)\n",
    "win_accuracy_knn = conf_matrix_knn[1, 1] / conf_matrix_knn[1].sum()  # Accuracy for 'Win' (1)\n",
    "\n",
    "# Best parameters and score from GridSearchCV\n",
    "best_params_grid_knn = grid_search_knn.best_params_\n",
    "print(f\"Best parameters from GridSearchCV (KNN): {best_params_grid_knn}\")\n",
    "print(f\"Best score from GridSearchCV (KNN): {grid_search_knn.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate the KNN model on the test set\n",
    "test_accuracy_knn = grid_search_knn.score(X_test_binary, y_test_binary)\n",
    "print(f\"Test set accuracy (KNN): {test_accuracy_knn:.4f}\")\n",
    "\n",
    "# Check if KNN model results already exist and compare test accuracies\n",
    "if \"K-Nearest Neighbors - Win/Loss\" not in results_df_win_notwin[\"Model\"].values:\n",
    "    # No previous KNN entry exists, so add it\n",
    "    new_row_knn = pd.DataFrame({\n",
    "        \"Model\": [\"K-Nearest Neighbors - Win/Loss\"],\n",
    "        \"Best Score\": [grid_search_knn.best_score_],\n",
    "        \"Best Params\": [best_params_grid_knn],\n",
    "        \"Win Accuracy\": [win_accuracy_knn],\n",
    "        \"Loss Accuracy\": [loss_accuracy_knn],\n",
    "        \"Test Accuracy\": [test_accuracy_knn]\n",
    "    })\n",
    "    results_df_win_notwin = pd.concat([results_df_win_notwin, new_row_knn], ignore_index=True)\n",
    "\n",
    "else:\n",
    "    # Previous KNN entry exists, compare and replace if new test accuracy is better\n",
    "    previous_test_accuracy = results_df_win_notwin[results_df_win_notwin[\"Model\"] == \"K-Nearest Neighbors - Win/Loss\"][\"Test Accuracy\"].values[0]\n",
    "    \n",
    "    if test_accuracy_knn > previous_test_accuracy:\n",
    "        # Remove the old KNN entry\n",
    "        results_df_win_notwin = results_df_win_notwin[results_df_win_notwin[\"Model\"] != \"K-Nearest Neighbors - Win/Loss\"]\n",
    "        \n",
    "        # Append the new KNN results to the DataFrame\n",
    "        new_row_knn = pd.DataFrame({\n",
    "            \"Model\": [\"K-Nearest Neighbors - Win/Loss\"],\n",
    "            \"Best Score\": [grid_search_knn.best_score_],\n",
    "            \"Best Params\": [best_params_grid_knn],\n",
    "            \"Win Accuracy\": [win_accuracy_knn],\n",
    "            \"Loss Accuracy\": [loss_accuracy_knn],\n",
    "            \"Test Accuracy\": [test_accuracy_knn]\n",
    "        })\n",
    "        results_df_win_loss = pd.concat([results_df_win_notwin, new_row_knn], ignore_index=True)\n",
    "\n",
    "# Save the updated DataFrame to the CSV file\n",
    "results_df_win_notwin.to_csv(\"win_loss_tuning_results.csv\", index=False)\n",
    "\n",
    "# Display the updated results DataFrame\n",
    "results_df_win_notwin\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 426, number of negative: 510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 919\n",
      "[LightGBM] [Info] Number of data points in the train set: 936, number of used features: 62\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.455128 -> initscore=-0.179971\n",
      "[LightGBM] [Info] Start training from score -0.179971\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best parameters from GridSearchCV (LGBM): {'classifier__colsample_bytree': 0.8, 'classifier__learning_rate': 0.01, 'classifier__max_depth': 10, 'classifier__min_child_samples': 30, 'classifier__n_estimators': 200, 'classifier__num_leaves': 31, 'classifier__reg_alpha': 0.5, 'classifier__reg_lambda': 0.5, 'classifier__subsample': 0.8}\n",
      "Best score from GridSearchCV (LGBM): 0.6143\n",
      "Test set accuracy (LGBM): 0.6605\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best Score</th>\n",
       "      <th>Best Params</th>\n",
       "      <th>Win Accuracy</th>\n",
       "      <th>Loss Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost - Win/Loss</td>\n",
       "      <td>0.615349</td>\n",
       "      <td>{'classifier__colsample_bytree': 0.8, 'classif...</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.657609</td>\n",
       "      <td>0.651235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost - Win/Loss</td>\n",
       "      <td>0.583391</td>\n",
       "      <td>{'classifier__colsample_bytree': 0.8, 'classif...</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.679348</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest - Win/Loss</td>\n",
       "      <td>0.640983</td>\n",
       "      <td>{'classifier__bootstrap': True, 'classifier__m...</td>\n",
       "      <td>0.578571</td>\n",
       "      <td>0.701087</td>\n",
       "      <td>0.648148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression - Win/Loss</td>\n",
       "      <td>0.644166</td>\n",
       "      <td>{'classifier__C': 0.01, 'classifier__class_wei...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.679012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbors - Win/Loss</td>\n",
       "      <td>0.628189</td>\n",
       "      <td>{'classifier__metric': 'manhattan', 'classifie...</td>\n",
       "      <td>0.564286</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.638889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LGBM - Win/Loss</td>\n",
       "      <td>0.614316</td>\n",
       "      <td>{'classifier__colsample_bytree': 0.8, 'classif...</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.660494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Model  Best Score  \\\n",
       "0              XGBoost - Win/Loss    0.615349   \n",
       "1              XGBoost - Win/Loss    0.583391   \n",
       "2        Random Forest - Win/Loss    0.640983   \n",
       "3  Logistic Regression - Win/Loss    0.644166   \n",
       "4  K-Nearest Neighbors - Win/Loss    0.628189   \n",
       "5                 LGBM - Win/Loss    0.614316   \n",
       "\n",
       "                                         Best Params  Win Accuracy  \\\n",
       "0  {'classifier__colsample_bytree': 0.8, 'classif...      0.642857   \n",
       "1  {'classifier__colsample_bytree': 0.8, 'classif...      0.650000   \n",
       "2  {'classifier__bootstrap': True, 'classifier__m...      0.578571   \n",
       "3  {'classifier__C': 0.01, 'classifier__class_wei...      0.600000   \n",
       "4  {'classifier__metric': 'manhattan', 'classifie...      0.564286   \n",
       "5  {'classifier__colsample_bytree': 0.8, 'classif...      0.614286   \n",
       "\n",
       "   Loss Accuracy  Test Accuracy  \n",
       "0       0.657609       0.651235  \n",
       "1       0.679348       0.666667  \n",
       "2       0.701087       0.648148  \n",
       "3       0.739130       0.679012  \n",
       "4       0.695652       0.638889  \n",
       "5       0.695652       0.660494  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Further narrowed parameter grid for LGBM for faster execution (~a few minutes)\n",
    "param_grid_lgbm = {\n",
    "    'classifier__n_estimators': [150, 200],  # Close to 200\n",
    "    'classifier__max_depth': [10, 15],  # Focus around 15\n",
    "    'classifier__learning_rate': [0.01],  # Fix at 0.01 since it's already a good hit\n",
    "    'classifier__num_leaves': [31],  # Fix at 31 \n",
    "    'classifier__subsample': [0.8],  # Fix at 0.8\n",
    "    'classifier__colsample_bytree': [0.8],  # Fix at 0.8\n",
    "    'classifier__min_child_samples': [30],  # Fix at 30 \n",
    "    'classifier__reg_alpha': [0.5],  # Fix at 0.5 \n",
    "    'classifier__reg_lambda': [0.5]  # Fix at 0.5 \n",
    "}\n",
    "\n",
    "# Replace the classifier in the pipeline with LGBMClassifier\n",
    "pipeline.steps[-1] = ('classifier', LGBMClassifier(n_jobs=-1, random_state=42))\n",
    "\n",
    "# Set up GridSearchCV for LGBM\n",
    "grid_search_lgbm = GridSearchCV(pipeline, param_grid_lgbm, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the LGBM model\n",
    "grid_search_lgbm.fit(X_train_binary, y_train_binary)\n",
    "\n",
    "# Save the best LGBM model to a file using joblib\n",
    "joblib.dump(grid_search_lgbm.best_estimator_, 'best_lgbm_model.pkl')\n",
    "\n",
    "# Get predictions on the test set\n",
    "y_pred_lgbm = grid_search_lgbm.predict(X_test_binary)\n",
    "\n",
    "# Confusion matrix for binary classification (1 = Win, 0 = Loss)\n",
    "conf_matrix_lgbm = confusion_matrix(y_test_binary, y_pred_lgbm, labels=[0, 1])\n",
    "\n",
    "# Calculate accuracy for Win and Loss classes\n",
    "loss_accuracy_lgbm = conf_matrix_lgbm[0, 0] / conf_matrix_lgbm[0].sum()  # Accuracy for 'Loss' (0)\n",
    "win_accuracy_lgbm = conf_matrix_lgbm[1, 1] / conf_matrix_lgbm[1].sum()  # Accuracy for 'Win' (1)\n",
    "\n",
    "# Best parameters and score from GridSearchCV\n",
    "best_params_grid_lgbm = grid_search_lgbm.best_params_\n",
    "print(f\"Best parameters from GridSearchCV (LGBM): {best_params_grid_lgbm}\")\n",
    "print(f\"Best score from GridSearchCV (LGBM): {grid_search_lgbm.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate the LGBM model on the test set\n",
    "test_accuracy_lgbm = grid_search_lgbm.score(X_test_binary, y_test_binary)\n",
    "print(f\"Test set accuracy (LGBM): {test_accuracy_lgbm:.4f}\")\n",
    "\n",
    "# Check if the current LGBM test accuracy is better than the previous best for LGBM\n",
    "if \"LGBM - Win/Loss\" not in results_df_win_notwin[\"Model\"].values:\n",
    "    # No previous LGBM entry exists, so add it\n",
    "    new_row_lgbm = pd.DataFrame({\n",
    "        \"Model\": [\"LGBM - Win/Loss\"],\n",
    "        \"Best Score\": [grid_search_lgbm.best_score_],\n",
    "        \"Best Params\": [best_params_grid_lgbm],\n",
    "        \"Win Accuracy\": [win_accuracy_lgbm],\n",
    "        \"Loss Accuracy\": [loss_accuracy_lgbm],\n",
    "        \"Test Accuracy\": [test_accuracy_lgbm]\n",
    "    })\n",
    "    results_df_win_notwin = pd.concat([results_df_win_notwin, new_row_lgbm], ignore_index=True)\n",
    "\n",
    "else:\n",
    "    # Previous LGBM entry exists, compare and replace if new test accuracy is better\n",
    "    previous_test_accuracy = results_df_win_notwin[results_df_win_notwin[\"Model\"] == \"LGBM - Win/Loss\"][\"Test Accuracy\"].values[0]\n",
    "    \n",
    "    if test_accuracy_lgbm > previous_test_accuracy:\n",
    "        # Remove the old LGBM entry\n",
    "        results_df_win_notwin = results_df_win_notwin[results_df_win_notwin[\"Model\"] != \"LGBM - Win/Loss\"]\n",
    "        \n",
    "        # Append the new LGBM results to the DataFrame\n",
    "        new_row_lgbm = pd.DataFrame({\n",
    "            \"Model\": [\"LGBM - Win/Loss\"],\n",
    "            \"Best Score\": [grid_search_lgbm.best_score_],\n",
    "            \"Best Params\": [best_params_grid_lgbm],\n",
    "            \"Win Accuracy\": [win_accuracy_lgbm],\n",
    "            \"Loss Accuracy\": [loss_accuracy_lgbm],\n",
    "            \"Test Accuracy\": [test_accuracy_lgbm]\n",
    "        })\n",
    "        results_df_win_notwin = pd.concat([results_df_win_notwin, new_row_lgbm], ignore_index=True)\n",
    "\n",
    "# Save the updated DataFrame to the CSV file\n",
    "results_df_win_notwin.to_csv(\"win_loss_tuning_results.csv\", index=False)\n",
    "\n",
    "# Display the updated results DataFrame\n",
    "results_df_win_notwin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6 AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\czarn\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters from GridSearchCV (AdaBoost): {'classifier__algorithm': 'SAMME.R', 'classifier__learning_rate': 0.01, 'classifier__n_estimators': 200}\n",
      "Best score from GridSearchCV (AdaBoost): 0.6335\n",
      "Test set accuracy (AdaBoost): 0.6759\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best Score</th>\n",
       "      <th>Best Params</th>\n",
       "      <th>Win Accuracy</th>\n",
       "      <th>Loss Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost - Win/Loss</td>\n",
       "      <td>0.615349</td>\n",
       "      <td>{'classifier__colsample_bytree': 0.8, 'classif...</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.657609</td>\n",
       "      <td>0.651235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost - Win/Loss</td>\n",
       "      <td>0.583391</td>\n",
       "      <td>{'classifier__colsample_bytree': 0.8, 'classif...</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.679348</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest - Win/Loss</td>\n",
       "      <td>0.640983</td>\n",
       "      <td>{'classifier__bootstrap': True, 'classifier__m...</td>\n",
       "      <td>0.578571</td>\n",
       "      <td>0.701087</td>\n",
       "      <td>0.648148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression - Win/Loss</td>\n",
       "      <td>0.644166</td>\n",
       "      <td>{'classifier__C': 0.01, 'classifier__class_wei...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.679012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbors - Win/Loss</td>\n",
       "      <td>0.628189</td>\n",
       "      <td>{'classifier__metric': 'manhattan', 'classifie...</td>\n",
       "      <td>0.564286</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.638889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LGBM - Win/Loss</td>\n",
       "      <td>0.614316</td>\n",
       "      <td>{'classifier__colsample_bytree': 0.8, 'classif...</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.660494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AdaBoost - Win/Loss</td>\n",
       "      <td>0.633513</td>\n",
       "      <td>{'classifier__algorithm': 'SAMME.R', 'classifi...</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.842391</td>\n",
       "      <td>0.675926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Model  Best Score  \\\n",
       "0              XGBoost - Win/Loss    0.615349   \n",
       "1              XGBoost - Win/Loss    0.583391   \n",
       "2        Random Forest - Win/Loss    0.640983   \n",
       "3  Logistic Regression - Win/Loss    0.644166   \n",
       "4  K-Nearest Neighbors - Win/Loss    0.628189   \n",
       "5                 LGBM - Win/Loss    0.614316   \n",
       "6             AdaBoost - Win/Loss    0.633513   \n",
       "\n",
       "                                         Best Params  Win Accuracy  \\\n",
       "0  {'classifier__colsample_bytree': 0.8, 'classif...      0.642857   \n",
       "1  {'classifier__colsample_bytree': 0.8, 'classif...      0.650000   \n",
       "2  {'classifier__bootstrap': True, 'classifier__m...      0.578571   \n",
       "3  {'classifier__C': 0.01, 'classifier__class_wei...      0.600000   \n",
       "4  {'classifier__metric': 'manhattan', 'classifie...      0.564286   \n",
       "5  {'classifier__colsample_bytree': 0.8, 'classif...      0.614286   \n",
       "6  {'classifier__algorithm': 'SAMME.R', 'classifi...      0.457143   \n",
       "\n",
       "   Loss Accuracy  Test Accuracy  \n",
       "0       0.657609       0.651235  \n",
       "1       0.679348       0.666667  \n",
       "2       0.701087       0.648148  \n",
       "3       0.739130       0.679012  \n",
       "4       0.695652       0.638889  \n",
       "5       0.695652       0.660494  \n",
       "6       0.842391       0.675926  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Define a parameter grid for AdaBoost to run for ~30 minutes\n",
    "param_grid_adaboost = {\n",
    "    'classifier__n_estimators': [50, 100, 200, 500],  # Number of trees\n",
    "    'classifier__learning_rate': [0.001, 0.01, 0.1, 1.0],  # Learning rate\n",
    "    'classifier__algorithm': ['SAMME', 'SAMME.R']  # Boosting algorithms\n",
    "}\n",
    "\n",
    "# Replace the classifier in the pipeline with AdaBoostClassifier\n",
    "pipeline.steps[-1] = ('classifier', AdaBoostClassifier(random_state=42))\n",
    "\n",
    "# Set up GridSearchCV for AdaBoost\n",
    "grid_search_adaboost = GridSearchCV(pipeline, param_grid_adaboost, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the AdaBoost model\n",
    "grid_search_adaboost.fit(X_train_binary, y_train_binary)\n",
    "\n",
    "# Save the best AdaBoost model to a file using joblib\n",
    "joblib.dump(grid_search_adaboost.best_estimator_, 'best_adaboost_model.pkl')\n",
    "\n",
    "# Get predictions on the test set\n",
    "y_pred_adaboost = grid_search_adaboost.predict(X_test_binary)\n",
    "\n",
    "# Confusion matrix for binary classification (1 = Win, 0 = Loss)\n",
    "conf_matrix_adaboost = confusion_matrix(y_test_binary, y_pred_adaboost, labels=[0, 1])\n",
    "\n",
    "# Calculate accuracy for Win and Loss classes\n",
    "loss_accuracy_adaboost = conf_matrix_adaboost[0, 0] / conf_matrix_adaboost[0].sum()  # Accuracy for 'Loss' (0)\n",
    "win_accuracy_adaboost = conf_matrix_adaboost[1, 1] / conf_matrix_adaboost[1].sum()  # Accuracy for 'Win' (1)\n",
    "\n",
    "# Best parameters and score from GridSearchCV\n",
    "best_params_grid_adaboost = grid_search_adaboost.best_params_\n",
    "print(f\"Best parameters from GridSearchCV (AdaBoost): {best_params_grid_adaboost}\")\n",
    "print(f\"Best score from GridSearchCV (AdaBoost): {grid_search_adaboost.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate the AdaBoost model on the test set\n",
    "test_accuracy_adaboost = grid_search_adaboost.score(X_test_binary, y_test_binary)\n",
    "print(f\"Test set accuracy (AdaBoost): {test_accuracy_adaboost:.4f}\")\n",
    "\n",
    "# Initialize results_df_win_notwin if it doesn't exist\n",
    "if 'results_df_win_notwin' not in locals():\n",
    "    results_df_win_notwin = pd.DataFrame(columns=[\"Model\", \"Best Score\", \"Best Params\", \"Win Accuracy\", \"Loss Accuracy\", \"Test Accuracy\"])\n",
    "\n",
    "# Check if the current AdaBoost test accuracy is better than the previous best for AdaBoost\n",
    "if \"AdaBoost - Win/Loss\" not in results_df_win_notwin[\"Model\"].values or test_accuracy_adaboost > results_df_win_notwin[results_df_win_notwin[\"Model\"] == \"AdaBoost - Win/Loss\"][\"Test Accuracy\"].values[0]:\n",
    "\n",
    "    # Append the AdaBoost results to the existing results DataFrame\n",
    "    new_row_adaboost = pd.DataFrame({\n",
    "        \"Model\": [\"AdaBoost - Win/Loss\"],\n",
    "        \"Best Score\": [grid_search_adaboost.best_score_],\n",
    "        \"Best Params\": [best_params_grid_adaboost],\n",
    "        \"Win Accuracy\": [win_accuracy_adaboost],\n",
    "        \"Loss Accuracy\": [loss_accuracy_adaboost],\n",
    "        \"Test Accuracy\": [test_accuracy_adaboost]\n",
    "    })\n",
    "\n",
    "    # Append the new row with AdaBoost results to the existing DataFrame\n",
    "    results_df_win_notwin = pd.concat([results_df_win_notwin, new_row_adaboost], ignore_index=True)\n",
    "\n",
    "    # Save the updated DataFrame to the CSV file\n",
    "    results_df_win_notwin.to_csv(\"win_loss_tuning_results.csv\", index=False)\n",
    "\n",
    "# Display the updated results DataFrame\n",
    "results_df_win_notwin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.7 Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters from GridSearchCV (Gradient Boosting): {'classifier__learning_rate': 0.01, 'classifier__max_depth': 3, 'classifier__max_features': 'sqrt', 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 100, 'classifier__subsample': 0.8}\n",
      "Best score from GridSearchCV (Gradient Boosting): 0.6378\n",
      "Test set accuracy (Gradient Boosting): 0.6605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\czarn\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\ma\\core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best Score</th>\n",
       "      <th>Best Params</th>\n",
       "      <th>Win Accuracy</th>\n",
       "      <th>Loss Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost - Win/Loss</td>\n",
       "      <td>0.615349</td>\n",
       "      <td>{'classifier__colsample_bytree': 0.8, 'classif...</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.657609</td>\n",
       "      <td>0.651235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost - Win/Loss</td>\n",
       "      <td>0.583391</td>\n",
       "      <td>{'classifier__colsample_bytree': 0.8, 'classif...</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.679348</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest - Win/Loss</td>\n",
       "      <td>0.640983</td>\n",
       "      <td>{'classifier__bootstrap': True, 'classifier__m...</td>\n",
       "      <td>0.578571</td>\n",
       "      <td>0.701087</td>\n",
       "      <td>0.648148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression - Win/Loss</td>\n",
       "      <td>0.644166</td>\n",
       "      <td>{'classifier__C': 0.01, 'classifier__class_wei...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.679012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbors - Win/Loss</td>\n",
       "      <td>0.628189</td>\n",
       "      <td>{'classifier__metric': 'manhattan', 'classifie...</td>\n",
       "      <td>0.564286</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.638889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LGBM - Win/Loss</td>\n",
       "      <td>0.614316</td>\n",
       "      <td>{'classifier__colsample_bytree': 0.8, 'classif...</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.660494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AdaBoost - Win/Loss</td>\n",
       "      <td>0.633513</td>\n",
       "      <td>{'classifier__algorithm': 'SAMME.R', 'classifi...</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.842391</td>\n",
       "      <td>0.675926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gradient Boosting - Win/Loss</td>\n",
       "      <td>0.611130</td>\n",
       "      <td>{'classifier__learning_rate': 0.01, 'classifie...</td>\n",
       "      <td>0.421429</td>\n",
       "      <td>0.842391</td>\n",
       "      <td>0.660494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Model  Best Score  \\\n",
       "0              XGBoost - Win/Loss    0.615349   \n",
       "1              XGBoost - Win/Loss    0.583391   \n",
       "2        Random Forest - Win/Loss    0.640983   \n",
       "3  Logistic Regression - Win/Loss    0.644166   \n",
       "4  K-Nearest Neighbors - Win/Loss    0.628189   \n",
       "5                 LGBM - Win/Loss    0.614316   \n",
       "6             AdaBoost - Win/Loss    0.633513   \n",
       "7    Gradient Boosting - Win/Loss    0.611130   \n",
       "\n",
       "                                         Best Params  Win Accuracy  \\\n",
       "0  {'classifier__colsample_bytree': 0.8, 'classif...      0.642857   \n",
       "1  {'classifier__colsample_bytree': 0.8, 'classif...      0.650000   \n",
       "2  {'classifier__bootstrap': True, 'classifier__m...      0.578571   \n",
       "3  {'classifier__C': 0.01, 'classifier__class_wei...      0.600000   \n",
       "4  {'classifier__metric': 'manhattan', 'classifie...      0.564286   \n",
       "5  {'classifier__colsample_bytree': 0.8, 'classif...      0.614286   \n",
       "6  {'classifier__algorithm': 'SAMME.R', 'classifi...      0.457143   \n",
       "7  {'classifier__learning_rate': 0.01, 'classifie...      0.421429   \n",
       "\n",
       "   Loss Accuracy  Test Accuracy  \n",
       "0       0.657609       0.651235  \n",
       "1       0.679348       0.666667  \n",
       "2       0.701087       0.648148  \n",
       "3       0.739130       0.679012  \n",
       "4       0.695652       0.638889  \n",
       "5       0.695652       0.660494  \n",
       "6       0.842391       0.675926  \n",
       "7       0.842391       0.660494  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "param_grid_gb = {\n",
    "    'classifier__n_estimators': [100, 150, 200],  # Number of boosting stages\n",
    "    'classifier__max_depth': [3, 6, 8],  # Maximum depth of individual trees\n",
    "    'classifier__learning_rate': [0.01, 0.1],  # Shrinks contribution of each tree\n",
    "    'classifier__subsample': [0.8, 1.0],  # Fraction of samples to be used for fitting individual base learners\n",
    "    'classifier__min_samples_split': [2, 5],  # Minimum number of samples required to split an internal node\n",
    "    'classifier__min_samples_leaf': [1, 3],  # Minimum number of samples required to be at a leaf node\n",
    "    'classifier__max_features': ['sqrt', 'log2'],  # The number of features to consider when looking for the best split\n",
    "}\n",
    "\n",
    "# Replace the classifier in the pipeline with GradientBoostingClassifier\n",
    "pipeline.steps[-1] = ('classifier', GradientBoostingClassifier(random_state=1))\n",
    "\n",
    "# Set up GridSearchCV for Gradient Boosting\n",
    "grid_search_gb = GridSearchCV(pipeline, param_grid_gb, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the Gradient Boosting model\n",
    "grid_search_gb.fit(X_train_binary, y_train_binary)\n",
    "\n",
    "# Save the best model to a file using joblib\n",
    "joblib.dump(grid_search_gb.best_estimator_, 'best_gb_model.pkl')\n",
    "\n",
    "# Get predictions on the test set\n",
    "y_pred_gb = grid_search_gb.predict(X_test_binary)\n",
    "\n",
    "# Confusion matrix for binary classification (1 = Win, 0 = Loss)\n",
    "conf_matrix_gb = confusion_matrix(y_test_binary, y_pred_gb, labels=[0, 1])\n",
    "\n",
    "# Calculate accuracy for Win and Loss classes\n",
    "loss_accuracy_gb = conf_matrix_gb[0, 0] / conf_matrix_gb[0].sum()  # Accuracy for 'Loss' (0)\n",
    "win_accuracy_gb = conf_matrix_gb[1, 1] / conf_matrix_gb[1].sum()  # Accuracy for 'Win' (1)\n",
    "\n",
    "# Best parameters and score from GridSearchCV\n",
    "best_params_grid_gb = grid_search_gb.best_params_\n",
    "print(f\"Best parameters from GridSearchCV (Gradient Boosting): {best_params_grid_gb}\")\n",
    "print(f\"Best score from GridSearchCV (Gradient Boosting): {grid_search_gb.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate the Gradient Boosting model on the test set\n",
    "test_accuracy_gb = grid_search_gb.score(X_test_binary, y_test_binary)\n",
    "print(f\"Test set accuracy (Gradient Boosting): {test_accuracy_gb:.4f}\")\n",
    "\n",
    "# Initialize results_df_win_loss if it doesn't exist\n",
    "if 'results_df_win_notwin' not in locals():\n",
    "    results_df_win_notwin = pd.DataFrame(columns=[\"Model\", \"Best Score\", \"Best Params\", \"Win Accuracy\", \"Loss Accuracy\", \"Test Accuracy\"])\n",
    "\n",
    "# Check if the current Gradient Boosting test accuracy is better than the previous best for Gradient Boosting\n",
    "if \"Gradient Boosting - Win/Loss\" not in results_df_win_notwin[\"Model\"].values or test_accuracy_gb > results_df_win_notwin[results_df_win_notwin[\"Model\"] == \"Gradient Boosting - Win/Loss\"][\"Test Accuracy\"].values[0]:\n",
    "\n",
    "    # Append the Gradient Boosting results to the existing results DataFrame\n",
    "    new_row_gb = pd.DataFrame({\n",
    "        \"Model\": [\"Gradient Boosting - Win/Loss\"],\n",
    "        \"Best Score\": [grid_search_gb.best_score_],\n",
    "        \"Best Params\": [best_params_grid_gb],\n",
    "        \"Win Accuracy\": [win_accuracy_gb],\n",
    "        \"Loss Accuracy\": [loss_accuracy_gb],\n",
    "        \"Test Accuracy\": [test_accuracy_gb]\n",
    "    })\n",
    "\n",
    "    # Append the new row with Gradient Boosting results to the existing DataFrame\n",
    "    results_df_win_notwin = pd.concat([results_df_win_notwin, new_row_gb], ignore_index=True)\n",
    "\n",
    "    # Save the updated DataFrame to the CSV file\n",
    "    results_df_win_notwin.to_csv(\"win_notwin_tuning_results.csv\", index=False)\n",
    "\n",
    "# Display the updated results DataFrame\n",
    "results_df_win_notwin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I've tested few models and i'll go with XGB or Logistic Regression for my GameApp idea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Checking feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>num__team_overall</td>\n",
       "      <td>0.064634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>num__opponent_overall</td>\n",
       "      <td>0.046376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>num__team_defense</td>\n",
       "      <td>0.045909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>num__team_attack</td>\n",
       "      <td>0.043411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>cat__away_team_formation_3-1-4-2</td>\n",
       "      <td>0.040101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>num__opponent_defense</td>\n",
       "      <td>0.032867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>num__opponent_attack</td>\n",
       "      <td>0.027755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>num__team_midfield</td>\n",
       "      <td>0.026232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>cat__home_team_formation_3-5-2</td>\n",
       "      <td>0.024089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>cat__home_team_formation_3-4-1-2</td>\n",
       "      <td>0.024059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>cat__home_team_formation_4-4-2</td>\n",
       "      <td>0.023713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>cat__day_Fri</td>\n",
       "      <td>0.023179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>cat__referee_Marco Fritz</td>\n",
       "      <td>0.022575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>cat__referee_Bastian Dankert</td>\n",
       "      <td>0.022189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>cat__day_Sun</td>\n",
       "      <td>0.020673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>num__sh_last_4_games</td>\n",
       "      <td>0.020474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>num__sot_last_4_games</td>\n",
       "      <td>0.020444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>cat__referee_Harm Osmers</td>\n",
       "      <td>0.020386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>num__opponent_midfield</td>\n",
       "      <td>0.019839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>cat__home_team_formation_3-1-4-2</td>\n",
       "      <td>0.019746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>cat__referee_Christian Dingert</td>\n",
       "      <td>0.019664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>cat__home_team_formation_3-4-3</td>\n",
       "      <td>0.019126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>cat__away_team_formation_4-3-3</td>\n",
       "      <td>0.018953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>num__xga_last_4_games</td>\n",
       "      <td>0.018723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>num__opponent_ga_last_4_games</td>\n",
       "      <td>0.018285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>num__team_salary</td>\n",
       "      <td>0.018264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>cat__referee_Daniel Siebert</td>\n",
       "      <td>0.017850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>num__poss_last_4_games</td>\n",
       "      <td>0.017285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>num__opponent_avg_points_last_4_games</td>\n",
       "      <td>0.017269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>num__opponent_xga_last_4_games</td>\n",
       "      <td>0.017230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Feature  Importance\n",
       "0                       num__team_overall    0.064634\n",
       "4                   num__opponent_overall    0.046376\n",
       "3                       num__team_defense    0.045909\n",
       "1                        num__team_attack    0.043411\n",
       "50       cat__away_team_formation_3-1-4-2    0.040101\n",
       "7                   num__opponent_defense    0.032867\n",
       "5                    num__opponent_attack    0.027755\n",
       "2                      num__team_midfield    0.026232\n",
       "36         cat__home_team_formation_3-5-2    0.024089\n",
       "32       cat__home_team_formation_3-4-1-2    0.024059\n",
       "46         cat__home_team_formation_4-4-2    0.023713\n",
       "24                           cat__day_Fri    0.023179\n",
       "83               cat__referee_Marco Fritz    0.022575\n",
       "69           cat__referee_Bastian Dankert    0.022189\n",
       "27                           cat__day_Sun    0.020673\n",
       "13                   num__sh_last_4_games    0.020474\n",
       "14                  num__sot_last_4_games    0.020444\n",
       "81               cat__referee_Harm Osmers    0.020386\n",
       "6                  num__opponent_midfield    0.019839\n",
       "31       cat__home_team_formation_3-1-4-2    0.019746\n",
       "72         cat__referee_Christian Dingert    0.019664\n",
       "33         cat__home_team_formation_3-4-3    0.019126\n",
       "63         cat__away_team_formation_4-3-3    0.018953\n",
       "11                  num__xga_last_4_games    0.018723\n",
       "17          num__opponent_ga_last_4_games    0.018285\n",
       "20                       num__team_salary    0.018264\n",
       "74            cat__referee_Daniel Siebert    0.017850\n",
       "15                 num__poss_last_4_games    0.017285\n",
       "19  num__opponent_avg_points_last_4_games    0.017269\n",
       "18         num__opponent_xga_last_4_games    0.017230"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best XGBoost model from GridSearchCV\n",
    "best_xgb_model = grid_search_xgb.best_estimator_\n",
    "\n",
    "# Access feature importances from the XGBoost classifier\n",
    "importances = best_xgb_model.named_steps['classifier'].feature_importances_\n",
    "\n",
    "# Access the fitted preprocessor from the pipeline to get feature names\n",
    "preprocessor = best_xgb_model.named_steps['preprocessor']\n",
    "\n",
    "# Get the feature names after fitting the preprocessor\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "# Combine feature names with their importances\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "})\n",
    "\n",
    "# Sort features by importance (highest to lowest)\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the top features\n",
    "feature_importance_df.head(30)  # Show the top 10 features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Abs_Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>num__team_defense</td>\n",
       "      <td>0.152889</td>\n",
       "      <td>0.152889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>num__team_attack</td>\n",
       "      <td>0.146626</td>\n",
       "      <td>0.146626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>num__team_overall</td>\n",
       "      <td>0.113595</td>\n",
       "      <td>0.113595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>num__opponent_overall</td>\n",
       "      <td>-0.099848</td>\n",
       "      <td>0.099848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>num__opponent_defense</td>\n",
       "      <td>-0.088748</td>\n",
       "      <td>0.088748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>num__opponent_xga_last_4_games</td>\n",
       "      <td>0.081919</td>\n",
       "      <td>0.081919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>num__opponent_attack</td>\n",
       "      <td>-0.081898</td>\n",
       "      <td>0.081898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>num__sot_last_4_games</td>\n",
       "      <td>-0.081675</td>\n",
       "      <td>0.081675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>num__sh_last_4_games</td>\n",
       "      <td>0.080247</td>\n",
       "      <td>0.080247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>num__opponent_midfield</td>\n",
       "      <td>-0.078596</td>\n",
       "      <td>0.078596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>num__opponent_avg_points_last_4_games</td>\n",
       "      <td>-0.074369</td>\n",
       "      <td>0.074369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>cat__day_Sun</td>\n",
       "      <td>-0.074251</td>\n",
       "      <td>0.074251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>num__hour</td>\n",
       "      <td>0.071673</td>\n",
       "      <td>0.071673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>num__xga_last_4_games</td>\n",
       "      <td>-0.070652</td>\n",
       "      <td>0.070652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>num__team_midfield</td>\n",
       "      <td>0.068336</td>\n",
       "      <td>0.068336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>cat__home_team_formation_4-2-3-1</td>\n",
       "      <td>-0.067049</td>\n",
       "      <td>0.067049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>num__ga_last_4_games</td>\n",
       "      <td>-0.066876</td>\n",
       "      <td>0.066876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>cat__home_team_formation_3-1-4-2</td>\n",
       "      <td>-0.062099</td>\n",
       "      <td>0.062099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>cat__venue_Home</td>\n",
       "      <td>-0.058788</td>\n",
       "      <td>0.058788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>cat__day_Fri</td>\n",
       "      <td>0.058321</td>\n",
       "      <td>0.058321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>cat__away_team_formation_3-4-3</td>\n",
       "      <td>-0.055448</td>\n",
       "      <td>0.055448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>cat__home_team_formation_3-4-3</td>\n",
       "      <td>0.054555</td>\n",
       "      <td>0.054555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>cat__away_team_formation_3-1-4-2</td>\n",
       "      <td>0.053322</td>\n",
       "      <td>0.053322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>cat__referee_Deniz Aytekin</td>\n",
       "      <td>-0.043575</td>\n",
       "      <td>0.043575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>cat__referee_Harm Osmers</td>\n",
       "      <td>0.043568</td>\n",
       "      <td>0.043568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>cat__away_team_formation_4-1-4-1</td>\n",
       "      <td>-0.041028</td>\n",
       "      <td>0.041028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>cat__referee_Daniel Siebert</td>\n",
       "      <td>-0.037332</td>\n",
       "      <td>0.037332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>cat__referee_Benjamin Brand</td>\n",
       "      <td>-0.036777</td>\n",
       "      <td>0.036777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>num__xg_last_4_games</td>\n",
       "      <td>0.035248</td>\n",
       "      <td>0.035248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>cat__referee_Marco Fritz</td>\n",
       "      <td>0.034320</td>\n",
       "      <td>0.034320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Feature  Coefficient  Abs_Coefficient\n",
       "3                       num__team_defense     0.152889         0.152889\n",
       "1                        num__team_attack     0.146626         0.146626\n",
       "0                       num__team_overall     0.113595         0.113595\n",
       "4                   num__opponent_overall    -0.099848         0.099848\n",
       "7                   num__opponent_defense    -0.088748         0.088748\n",
       "18         num__opponent_xga_last_4_games     0.081919         0.081919\n",
       "5                    num__opponent_attack    -0.081898         0.081898\n",
       "14                  num__sot_last_4_games    -0.081675         0.081675\n",
       "13                   num__sh_last_4_games     0.080247         0.080247\n",
       "6                  num__opponent_midfield    -0.078596         0.078596\n",
       "19  num__opponent_avg_points_last_4_games    -0.074369         0.074369\n",
       "27                           cat__day_Sun    -0.074251         0.074251\n",
       "22                              num__hour     0.071673         0.071673\n",
       "11                  num__xga_last_4_games    -0.070652         0.070652\n",
       "2                      num__team_midfield     0.068336         0.068336\n",
       "41       cat__home_team_formation_4-2-3-1    -0.067049         0.067049\n",
       "9                    num__ga_last_4_games    -0.066876         0.066876\n",
       "31       cat__home_team_formation_3-1-4-2    -0.062099         0.062099\n",
       "23                        cat__venue_Home    -0.058788         0.058788\n",
       "24                           cat__day_Fri     0.058321         0.058321\n",
       "53         cat__away_team_formation_3-4-3    -0.055448         0.055448\n",
       "33         cat__home_team_formation_3-4-3     0.054555         0.054555\n",
       "50       cat__away_team_formation_3-1-4-2     0.053322         0.053322\n",
       "75             cat__referee_Deniz Aytekin    -0.043575         0.043575\n",
       "81               cat__referee_Harm Osmers     0.043568         0.043568\n",
       "58       cat__away_team_formation_4-1-4-1    -0.041028         0.041028\n",
       "74            cat__referee_Daniel Siebert    -0.037332         0.037332\n",
       "70            cat__referee_Benjamin Brand    -0.036777         0.036777\n",
       "10                   num__xg_last_4_games     0.035248         0.035248\n",
       "83               cat__referee_Marco Fritz     0.034320         0.034320"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best Logistic Regression model from GridSearchCV\n",
    "best_lr_model = grid_search_lr.best_estimator_\n",
    "\n",
    "# Access coefficients from the Logistic Regression classifier\n",
    "coefficients = best_lr_model.named_steps['classifier'].coef_[0]  # For binary classification, only one set of coefficients\n",
    "\n",
    "# Access the fitted preprocessor from the pipeline to get feature names\n",
    "preprocessor = best_lr_model.named_steps['preprocessor']\n",
    "\n",
    "# Get the feature names after fitting the preprocessor\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "# Combine feature names with their coefficients (importances)\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': coefficients\n",
    "})\n",
    "\n",
    "# Sort features by absolute value of coefficients (highest to lowest)\n",
    "feature_importance_df['Abs_Coefficient'] = feature_importance_df['Coefficient'].abs()\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Abs_Coefficient', ascending=False)\n",
    "\n",
    "# Display the top features\n",
    "feature_importance_df.head(30)  # Show the top 10 most important features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
